{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# nlptextdoc library source code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prepare the Python environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Install Anaconda and create a virtual environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download and install Anaconda for your platform : [Anaconda - Python 3.7](https://www.anaconda.com/distribution/#download-section)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Launch Anaconda Prompt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> conda create --name nlptextenv\n",
    "\n",
    "> conda activate nlptextenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Install pandas with pyarrow.feather file format support"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> conda install pandas\n",
    "\n",
    "> conda install pyarrow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure your version of pandas is > 0.24 and pyarrow is installed :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "INSTALLED VERSIONS\n",
      "------------------\n",
      "commit: None\n",
      "python: 3.7.3.final.0\n",
      "python-bits: 64\n",
      "OS: Windows\n",
      "OS-release: 10\n",
      "machine: AMD64\n",
      "processor: Intel64 Family 6 Model 158 Stepping 9, GenuineIntel\n",
      "byteorder: little\n",
      "LC_ALL: None\n",
      "LANG: None\n",
      "LOCALE: None.None\n",
      "\n",
      "pandas: 0.24.2\n",
      "pytest: 4.4.1\n",
      "pip: 19.0.3\n",
      "setuptools: 41.0.0\n",
      "Cython: 0.29.7\n",
      "numpy: 1.16.2\n",
      "scipy: None\n",
      "pyarrow: 0.11.1\n",
      "xarray: None\n",
      "IPython: 7.4.0\n",
      "sphinx: None\n",
      "patsy: None\n",
      "dateutil: 2.8.0\n",
      "pytz: 2019.1\n",
      "blosc: None\n",
      "bottleneck: None\n",
      "tables: None\n",
      "numexpr: None\n",
      "feather: None\n",
      "matplotlib: None\n",
      "openpyxl: None\n",
      "xlrd: None\n",
      "xlwt: None\n",
      "xlsxwriter: None\n",
      "lxml.etree: None\n",
      "bs4: None\n",
      "html5lib: None\n",
      "sqlalchemy: None\n",
      "pymysql: None\n",
      "psycopg2: None\n",
      "jinja2: 2.10.1\n",
      "s3fs: None\n",
      "fastparquet: None\n",
      "pandas_gbq: None\n",
      "pandas_datareader: None\n",
      "gcsfs: None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.show_versions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Install spaCy with french language support"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> conda install -c conda-forge spacy\n",
    "\n",
    "> python -m spacy download fr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure your version of spacy is > 2.1 and fr model is installed :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================== Info about spaCy ==============================\n",
      "\n",
      "spaCy version    2.1.3                         \n",
      "Location         C:\\Users\\laure\\Anaconda3\\envs\\spacy\\lib\\site-packages\\spacy\n",
      "Platform         Windows-10-10.0.18362-SP0     \n",
      "Python version   3.7.3                         \n",
      "Models           fr                            \n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install a spaCy language detector extension :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> pip install spacy-langdetect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if the language detection works :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy_langdetect import LanguageDetector\n",
    "\n",
    "def spacy_InitWithTokenizer():\n",
    "    nlp = spacy.load(\"fr_core_news_sm\",disable=[\"tagger\",\"ner\",\"parser\"])\n",
    "    return nlp\n",
    "\n",
    "def spacy_InitWithTokenizerAndLanguageDetector():\n",
    "    nlp = spacy_InitWithTokenizer()\n",
    "    nlp.add_pipe(nlp.create_pipe('sentencizer'), name=\"sentencizer\", last=True)\n",
    "    nlp.add_pipe(LanguageDetector(), name=\"language_detector\", last=True)\n",
    "    return nlp\n",
    "\n",
    "def spacy_DetectLanguage(doc):\n",
    "    return doc._.language[\"language\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3.99 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'fr'"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = spacy_InitWithTokenizerAndLanguageDetector()\n",
    "doc = nlp(\"Est-ce que le détecteur fonctionne ?\")\n",
    "%time spacy_DetectLanguage(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 How to run a Jupyter notebook in the context of a conda environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> conda activate nlptextenv\n",
    "\n",
    "> conda install ipykernel\n",
    "\n",
    "> python -m ipykernel install --user --name nlptextenv --display-name \"Python (nlptextenv)\"\n",
    "\n",
    "> jupyter notebook\n",
    "\n",
    "=> menu Kernel / Change kernel / Python (nlptextenv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check : locate the Jupyter config directories, kernels are configured in the 'kernels' subdirectory, in 'kernel.json' files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\laure\\AppData\\Roaming\\jupyter\n"
     ]
    }
   ],
   "source": [
    "from jupyter_core.paths import jupyter_data_dir\n",
    "print(jupyter_data_dir())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check : locate the python environment in use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\laure\\Anaconda3\\envs\\spacy\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Define technical utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def _memory_size(obj, seen=None):\n",
    "    size = sys.getsizeof(obj)\n",
    "    if seen is None:\n",
    "        seen = set()\n",
    "    obj_id = id(obj)\n",
    "    if obj_id in seen:\n",
    "        return 0\n",
    "    seen.add(obj_id)\n",
    "    if isinstance(obj, dict):\n",
    "        size += sum([_memory_size(v, seen) for v in obj.values()])\n",
    "        size += sum([_memory_size(k, seen) for k in obj.keys()])\n",
    "    elif hasattr(obj, '__dict__'):\n",
    "        size += _memory_size(obj.__dict__, seen)\n",
    "    elif hasattr(obj, '__iter__') and not isinstance(obj, (str, bytes, bytearray)):\n",
    "        size += sum([_memory_size(i, seen) for i in obj])\n",
    "    return size\n",
    "\n",
    "# OTHER OPTION specific to pandas dataframes\n",
    "# https://www.dataquest.io/blog/pandas-big-data/\n",
    "# df.info(memory_usage=\"deep\")\n",
    "\n",
    "def _file_size(filepath):\n",
    "    statinfo = os.stat(filepath)\n",
    "    return statinfo.st_size\n",
    "\n",
    "def _format_size_mb(size):\n",
    "    return int(size / 1024.0 / 102.4) / 10.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prepare the .NET environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Install Visual Studio 2019 community"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download and install [Microsoft Visual Studio 2019](https://visualstudio.microsoft.com/fr/downloads/) community edition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install only the following workload : .NET Core multiplatform development."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Clone and compile nlptextdoc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Launch Visual Studio 2019.\n",
    "\n",
    "Clone code\n",
    "- Repository URL : https://github.com/laurentprudhon/nlptextdoc.git\n",
    "- Choose a local directory for the solution\n",
    "\n",
    "Double click on the solution file : nlptextdoc.sln\n",
    "\n",
    "Select the \"Release\" configuration in the top toolbar.\n",
    "\n",
    "In the Solution Explorer :\n",
    "- right-click on the solution root => Generate solution\n",
    "- right-click on the projet \"nlptextdoc.cli\" => Open directory in File Explorer\n",
    "\n",
    "Navigate to the bin\\Release\\netcoreapp2.1 subdirectory :\n",
    "- this directory should contain 7 .dll files, including : nlptextdoc.cli.dll\n",
    "- copy the full path of this directory in the variable below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlptextdocExecPath = r\"C:\\Users\\laure\\source\\repos\\nlptextdoctemp\\nlptextdoc.cli\\bin\\Release\\netcoreapp2.1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the command line client and learn its syntax :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nlptexdoc extractor v1.0\n",
      "\n",
      "Crawls all the Html pages of a website and converts them to .nlp.txt structured text documents.\n",
      "All the extracted text documents are stored under a single directory named like the website.\n",
      "The .nlp.txt file format is described here : https://www.cognitivefactory.org/nlptextdocument/\n",
      "\n",
      "Features an advanced Html to text conversion algorithm :\n",
      "- tries to recover the logical structure of the document from the Html layout\n",
      "- interprets Css properties of the Html nodes to make this operation more reliable\n",
      "- preserves document / section / list / table grouping and nesting information\n",
      "\n",
      "Usage : nlptextdoc [rootUrl] [storageDirectory] [maxPagesCount=0] [minCrawlDelay=0]\n",
      " - rootUrl          : root Url of the website (or subfolder of a website) you want to crawl\n",
      " - storageDirectory : path to the disk directory where the website folder\n",
      " - maxPagesCount    : maximum number of pages extracted from the website (optional, default:100 000)\n",
      " - minCrawlDelay    : delay in milliseconds between two requests sent to the website (optional, default:100ms)\n",
      "\n",
      "Recommended process :\n",
      "1. Run the the tool for the first time with a low maxPagesCount (for example 500) and no crawl delay\n",
      "2. Open the log file \"httprequests.log.csv\" (created at the root of the website directory) in a spreadsheet\n",
      "3. Check for Http \"Forbidden\" answers, and test if the url is accessible when tested from a browser\n",
      "4. Try again with a non null minCrawlDelay, and continue to inscrease it until \"Forbidden\" errors disappear\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!dotnet \"{nlptextdocExecPath}/nlptextdoc.cli.dll\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Extract nlp text documents from websites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Identify popular websites to build your specific language model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List the public and open websites you would like to read to build a language model.\n",
    "\n",
    "PLEASE MAKE SURE THIS IS LEGAL in your country.\n",
    "\n",
    "For example in Europe : https://ec.europa.eu/digital-single-market/en/modernisation-eu-copyright-rules. \n",
    "\n",
    "> \"The mandatory exceptions that the proposed directive announced are related to: ... Text and data mining ...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
    "source": [
      "websites = [\"http://bourse.latribune.fr/\",\n",
      "            \"http://cercledelepargne.com/\",\n",
      "            \"http://finance.lelynx.fr/banques/\",\n",
      "            \"http://labourseauquotidien.fr/\",\n",
      "            \"http://lafourmiz.fr/\",\n",
      "            \"http://www.assurances.com/\",\n",
      "            \"http://www.banque.org/\",\n",
      "            \"http://www.banque-info.com/\",\n",
      "            \"http://www.bourse.fr/\",\n",
      "            \"http://www.boursedirect.fr/\",\n",
      "            \"http://www.capitaine-epargne.com/\",\n",
      "            \"http://www.cnp.fr/\",\n",
      "            \"http://www.cofinoga.fr/\",\n",
      "            \"http://www.comparabanques.fr/\",\n",
      "            \"http://www.comparalivrets.fr/\",\n",
      "            \"http://www.fbf.fr/\",\n",
      "            \"http://www.financo.fr/\",\n",
      "            \"http://www.generali.fr/\",\n",
      "            \"http://www.guide-epargne.com/\",\n",
      "            \"http://www.lemonde.fr/epargne/\",\n",
      "            \"http://www.leparisien.fr/economie/votre-argent/\",\n",
      "            \"http://www.lesaffaires.com/bourse\",\n",
      "            \"http://www.lesclesdelabanque.com\",\n",
      "            \"http://www.msn.com/fr-fr/finance\",\n",
      "            \"http://www.retraiteepargne.fr/\",\n",
      "            \"http://www.revue-banque.fr/\",\n",
      "            \"http://www.strategie-bourse.com/\",\n",
      "            \"http://www.zonebourse.com/\",\n",
      "            \"https://acpr.banque-france.fr/\",\n",
      "            \"https://banque.meilleurtaux.com/\",\n",
      "            \"https://bourse.lefigaro.fr/\",\n",
      "            \"https://compte-nickel.fr/\",\n",
      "            \"https://eko-by-ca.fr/\",\n",
      "            \"https://epargne.ooreka.fr/\",\n",
      "            \"https://ffa-assurance.fr/\",\n",
      "            \"https://fr.finance.yahoo.com/\",\n",
      "            \"https://humanis.com/\",\n",
      "            \"https://mabanque.bnpparibas/\",\n",
      "            \"https://mes-placements.fr/\",\n",
      "            \"https://n26.com/fr-fr/\",\n",
      "            \"https://particulier.apicil.com/\",\n",
      "            \"https://www.10meilleuresbanques.fr/\",\n",
      "            \"https://www.abcbourse.com/\",\n",
      "            \"https://www.afer.fr/\",\n",
      "            \"https://www.ag2rlamondiale.fr/\",\n",
      "            \"https://www.agpm.fr/\",\n",
      "            \"https://www.allianz.fr/\",\n",
      "            \"https://www.allianzbanque.fr/\",\n",
      "            \"https://www.amaguiz.com/\",\n",
      "            \"https://www.ameli.fr/\",\n",
      "            \"https://www.amundi.fr/fr_part\",\n",
      "            \"https://www.arkea.com/\",\n",
      "            \"https://www.assurland.com/\",\n",
      "            \"https://www.aviva.fr/\",\n",
      "            \"https://www.axa.fr/\",\n",
      "            \"https://www.banque.fr/\",\n",
      "            \"https://www.banque-casino.fr/\",\n",
      "            \"https://www.banque-edel.fr/\",\n",
      "            \"https://www.banque-france.fr/\",\n",
      "            \"https://www.banquepopulaire.fr/\",\n",
      "            \"https://www.banquesenligne.org/\",\n",
      "            \"https://www.bforbank.com/\",\n",
      "            \"https://www.boursedeparis.fr/\",\n",
      "            \"https://www.boursier.com/\",\n",
      "            \"https://www.boursorama.com/\",\n",
      "            \"https://www.boursorama-banque.com/\",\n",
      "            \"https://www.bred.fr/\",\n",
      "            \"https://www.ca-alsace-vosges.fr/\",\n",
      "            \"https://www.caisse-epargne.fr/\",\n",
      "            \"https://www.carrefour-banque.fr/\",\n",
      "            \"https://www.cbanque.com/\",\n",
      "            \"https://www.cetelem.fr/\",\n",
      "            \"https://www.challenges.fr/tag_theme/banque_876/\",\n",
      "            \"https://www.cic.fr/\",\n",
      "            \"https://www.cofidis.fr/\",\n",
      "            \"https://www.credit-cooperatif.coop/\",\n",
      "            \"https://www.credit-du-nord.fr/\",\n",
      "            \"https://www.credit-et-banque.com/\",\n",
      "            \"https://www.creditfoncier.fr/\",\n",
      "            \"https://www.creditmutuel.fr/\",\n",
      "            \"https://www.culturebanque.com/\",\n",
      "            \"https://www.diac.fr/\",\n",
      "            \"https://www.direct-assurance.fr/\",\n",
      "            \"https://www.economie.gouv.fr/\",\n",
      "            \"https://www.empruntis.com/epargne/\",\n",
      "            \"https://www.en-bourse.fr/\",\n",
      "            \"https://www.eurofil.com/\",\n",
      "            \"https://www.fortuneo.fr/\",\n",
      "            \"https://www.francetransactions.com/\",\n",
      "            \"https://www.gan.fr/\",\n",
      "            \"https://www.groupama.fr/\",\n",
      "            \"https://www.hellobank.fr/\",\n",
      "            \"https://www.home.saxo/fr-fr/\",\n",
      "            \"https://www.hsbc.fr/\",\n",
      "            \"https://www.impots.gouv.fr/portail/\",\n",
      "            \"https://www.ing.fr/banque-en-ligne/\",\n",
      "            \"https://www.labanquepostale.fr/\",\n",
      "            \"https://www.lcl.fr/\",\n",
      "            \"https://www.lerevenu.com/\",\n",
      "            \"https://www.lesechos.fr/finance-marches/\",\n",
      "            \"https://www.lesfurets.com/\",\n",
      "            \"https://www.lolivier.fr/\",\n",
      "            \"https://www.mae.fr/\",\n",
      "            \"https://www.maif.fr/\",\n",
      "            \"https://www.matmut.fr/\",\n",
      "            \"https://www.mma.fr/\",\n",
      "            \"https://www.monabanq.com/fr/index.html\",\n",
      "            \"https://www.mon-epargne.com/\",\n",
      "            \"https://www.montepaschi-banque.fr/fr/\",\n",
      "            \"https://www.natixis.com/\",\n",
      "            \"https://www.oney.fr/\",\n",
      "            \"https://www.orangebank.fr/\",\n",
      "            \"https://www.ouest-france.fr/economie/banques-finance/\",\n",
      "            \"https://www.palatine.fr/\",\n",
      "            \"https://www.panorabanques.com/\",\n",
      "            \"https://www.probtp.com/\",\n",
      "            \"https://www.psabanque.fr/\",\n",
      "            \"https://www.quechoisir.org/thematique-banque-credit-t111/\",\n",
      "            \"https://www.revolut.com/fr-FR/\",\n",
      "            \"https://www.service-public.fr/particuliers/vosdroits/N19803\",\n",
      "            \"https://www.smc.fr/\",\n",
      "            \"https://www.societegenerale.fr/\",\n",
      "            \"https://www.sofinco.fr/\",\n",
      "            \"https://www.toutsurmesfinances.com/\",\n",
      "            \"https://www.tradingsat.com/\",\n",
      "            \"https://www.usine-digitale.fr/banque/\",\n",
      "            \"https://www.younited-credit.com/\"]\n",
      "\n",
      "len(websites)"
    ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Extract raw text from these websites in a local directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a local directory to store the extracted nlp text documents : be careful, this directory may contain several gigabytes of data at the end of the process.\n",
    "\n",
    "IMPORTANT : **the \"magic\" \\\\\\\\?\\ prefix in the root path is mandatory on Windows** to enable long file names support in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "rootdir = Path(r\"\\\\?\\C:\\Users\\laure\\Desktop\\nlptextdoc-data-201907\")\n",
    "rootdir.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by extracting only a few documents (for example 100) from each webiste, to test if they are accessible and if everything works as expected :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxPagesCount = 100\n",
    "\n",
    "for websiteUrl in websites:\n",
    "    !dotnet \"{nlptextdocExecPath}/nlptextdoc.cli.dll\" {websiteUrl} {str(rootdir)} {maxPagesCount}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the local root directory, the extraction program creates one subdirectory per website.\n",
    "\n",
    "Each website subdirectory contains :\n",
    "- one log file called **httprequests.log.csv**\n",
    "- subdirectories reproducing the website tree structure\n",
    "- one **nlp.txt text document** for each extracted html page in this tree structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the following page for a **description of the nlptextdoc format** : https://github.com/laurentprudhon/nlptextdoc/blob/master/README.md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if all the websites were correctly extracted :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "def getWebsiteName(websiteurl):\n",
    "    url = urlparse(websiteurl)\n",
    "    websitename = url.netloc\n",
    "    return websitename\n",
    "\n",
    "def getWebsiteDir(rootdir, websitename):\n",
    "    websitedir = rootdir / websitename\n",
    "    return websitedir\n",
    "\n",
    "def loadExtractionLogs(websitedir):\n",
    "    return pd.read_csv(websitedir / \"httprequests.log.csv\",delimiter=\";\")\n",
    "\n",
    "def getExtractionStats(websites):\n",
    "    websiteNames = []\n",
    "    requestsCount = []\n",
    "    statusCounts = []    \n",
    "    errorTypes = [\"OK\",\"NotFound\",\"Redirect\",\"NoContent\",\"Forbidden\",\"BadRequest\",\"Moved\"]\n",
    "    for errorType in errorTypes:\n",
    "        statusCounts.append([])\n",
    "    for websiteurl in websites:\n",
    "        website = getWebsiteName(websiteurl)\n",
    "        print(f\"Checking extraction logs for website {website} ...\")\n",
    "        websitedir = getWebsiteDir(rootdir, website)\n",
    "        logsdf = loadExtractionLogs(websitedir)\n",
    "        logsstatus = logsdf[\"Status code\"].value_counts()\n",
    "        websiteNames.append(website)\n",
    "        requestsCount.append(len(logsdf))\n",
    "        for idx,errorType in enumerate(errorTypes):\n",
    "            statusCounts[idx].append(logsstatus[errorType] if errorType in logsstatus else 0)\n",
    "    dictResult = {}\n",
    "    dictResult[\"Website\"] = websiteNames\n",
    "    dictResult[\"Requests\"] = requestsCount\n",
    "    for idx,errorType in enumerate(errorTypes):\n",
    "        dictResult[errorType] = statusCounts[idx]\n",
    "    return pd.DataFrame(dictResult)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractionStats = getExtractionStats(websites)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractionStats[extractionStats[\"Requests\"] != extractionStats[\"OK\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each website with http error codes, open the log file **httprequests.log.csv** and see if something needs to be fixed.\n",
    "\n",
    "Use the code below to test if the errors :\n",
    "- were temporary, a consequence of a the high request rate the extraction program : then relaunch the extraction of the website with a bigger minCrawlDelay\n",
    "- are a real problem in the source website : just ignore them and continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from urllib.error import HTTPError\n",
    "\n",
    "def checkExtractionLogsByErrorType(logsdf):\n",
    "    errorTypes = [\"NotFound\",\"Redirect\",\"NoContent\",\"Forbidden\",\"BadRequest\",\"Moved\"]\n",
    "    urls = []\n",
    "    extractionStatus = []\n",
    "    checkedStatus = []\n",
    "    for errorType in errorTypes:\n",
    "        urlsWithError = logsdf[logsdf[\"Status code\"] == errorType][\"Url\"]\n",
    "        print(f\"Testing {len(urlsWithError)} URLs with error type {errorType} ...\")\n",
    "        for url in urlsWithError:\n",
    "            urls.append(url)\n",
    "            extractionStatus.append(errorType)\n",
    "            try:\n",
    "                resp = urlopen(url)\n",
    "                checkedStatus.append(resp.getcode())\n",
    "            except HTTPError as he:\n",
    "                checkedStatus.append(he.code)\n",
    "    checksdf = pd.DataFrame({\"Urls\" : urls, \"ExtractionStatus\" : extractionStatus, \"CheckedStatus\" : checkedStatus})\n",
    "    return checksdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "www.boursedirect.fr\n",
      "Testing 0 URLs with error type NotFound ...\n",
      "Testing 1 URLs with error type Redirect ...\n",
      "Testing 0 URLs with error type NoContent ...\n",
      "Testing 2 URLs with error type Forbidden ...\n",
      "Testing 0 URLs with error type BadRequest ...\n",
      "Testing 0 URLs with error type Moved ...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Urls</th>\n",
       "      <th>ExtractionStatus</th>\n",
       "      <th>CheckedStatus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://www.boursedirect.fr/priv/logoutPriv.php</td>\n",
       "      <td>Redirect</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://www.boursedirect.fr/fr/profil</td>\n",
       "      <td>Forbidden</td>\n",
       "      <td>403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://www.boursedirect.fr/fr/messagerie</td>\n",
       "      <td>Forbidden</td>\n",
       "      <td>403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Urls ExtractionStatus  \\\n",
       "0  http://www.boursedirect.fr/priv/logoutPriv.php         Redirect   \n",
       "1            http://www.boursedirect.fr/fr/profil        Forbidden   \n",
       "2        http://www.boursedirect.fr/fr/messagerie        Forbidden   \n",
       "\n",
       "   CheckedStatus  \n",
       "0            200  \n",
       "1            403  \n",
       "2            403  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "websiteIndex = 9\n",
    "websitename = getWebsiteName(websites[websiteIndex])\n",
    "print(websitename)\n",
    "\n",
    "websitedir = getWebsiteDir(rootdir, websitename)\n",
    "logsdf = loadExtractionLogs(websitedir)\n",
    "checkExtractionLogsByErrorType(logsdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When everything seems OK, relaunch the extraction code above with a much bigger maxPagesCount (for example 100 000)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Download publicly available french dictionaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a local subdirectory to store the french dictionaries :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictdir = rootdir / \"_dictionaries\"\n",
    "dictdir.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dictionary 1 : Dicollecte** - Open Source french dictionary for LibreOffice/OpenOffice\n",
    "\n",
    "Website : https://grammalecte.net/home.php?prj=fr.\n",
    "\n",
    "Licence : MPL : Mozilla Public License version 2.0  -  http://www.mozilla.org/MPL/2.0/.\n",
    "\n",
    "Download the latest \"Lexique\" on the [Grammalecte downloads page](https://grammalecte.net/download.php?prj=fr) :\n",
    "- open the zip file\n",
    "- copy only the \"lexique-dicollecte-fr-v*.txt file (for example : lexique-dicollecte-fr-v6.4.1.txt) in the local subdirectory\n",
    "\n",
    "Open the file in a text editor to see its self-descriptive format and contents.\n",
    "\n",
    "Store the file name in the variable below :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dicollectefile = dictdir / \"lexique-dicollecte-fr-v6.4.1.txt\"\n",
    "dicollectefile.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildDicollecteTags(dicollectefile):\n",
    "    dictionarydf = pd.read_csv(dicollectefile, sep=\"\\t\", skiprows=15)\n",
    "    dictionarydf.head()\n",
    "    dictionarytags = {}\n",
    "    for index, row in dictionarydf.iterrows():\n",
    "        token = row[\"Flexion\"]\n",
    "        tag = _convertDicollecteTagsToUnivDepTags(row[\"Étiquettes\"])\n",
    "        if(not (token in dictionarytags)):\n",
    "            dictionarytags[token] = tag\n",
    "        elif(not (tag in dictionarytags[token])):\n",
    "            dictionarytags[token] = dictionarytags[token] + \"|\" + tag\n",
    "    return dictionarytags\n",
    "\n",
    "def _convertDicollecteTagsToUnivDepTags(text):\n",
    "    if((\"adj\" in text) or (\"loc.adj\" in text)):\n",
    "        return \"ADJ\"\n",
    "    elif(\"prep\" in text):\n",
    "        return \"ADP\"\n",
    "    elif((\"adv\" in text) or (\"loc.adv\" in text)):\n",
    "        return \"ADV\"\n",
    "    elif((\"v0a\" in text) or (\"v0e\" in text) or (\"ppas\" in text)):\n",
    "        return \"AUX\"\n",
    "    elif(\"cjco\" in text):\n",
    "        return \"CCONJ\"\n",
    "    elif(\"det\" in text):\n",
    "        return \"DET\"\n",
    "    elif(\"interj\" in text):\n",
    "        return \"INTJ\"\n",
    "    elif(\"nom\" in text):\n",
    "        return \"NOUN\"\n",
    "    elif((\"nb\" in text) or (\"ord\" in text)):\n",
    "        return \"NUM\"\n",
    "    elif(\"pro\" in text):\n",
    "        return \"PRON\"\n",
    "    elif((\"prn\" in text) or (\"patr\" in text) or (\"npr\" in text)):\n",
    "        return \"PROPN\"\n",
    "    elif(\"cjsub\" in text):\n",
    "        return \"SCONJ\"\n",
    "    elif(\"symb\" in text):\n",
    "        return \"SYM\"\n",
    "    elif((\"v1\" in text) or (\"v2\" in text) or (\"v3\" in text) or (\"loc.verb\" in text)):\n",
    "        return \"VERB\"\n",
    "    else:\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicollecteTags = buildDicollecteTags(dicollectefile)\n",
    "dicollecteTags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dictionary 2 : UDLexicons Lefff** - Research resource from INRIA for the [Universal Dependencies](https://universaldependencies.org/) project\n",
    "\n",
    "Citation : Benoît Sagot. A multilingual collection of CoNLL-U-compatible morphological lexicons. Eleventh International Conference on Language Resources and Evaluation (LREC 2018), May 2018, Miyazaki, Japan. hal-01798798v2\n",
    "\n",
    "Paper : https://hal.inria.fr/hal-01798798v2/document\n",
    "\n",
    "Download the latest \"UDLexicons\" on [Benoît Sagot's resources page](http://alpage.inria.fr/~sagot/) :\n",
    "- open the zip file\n",
    "- copy only the \"UDLex_French-Lefff.conllul\" in the local directory\n",
    "- add a .txt extension to the file name\n",
    "\n",
    "Open the file in a text editor to see its self-descriptive format and contents.\n",
    "\n",
    "Store the file name in the variable below :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leffffile = dictdir / \"UDLex_French-Lefff.conllul.txt\"\n",
    "leffffile.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildLefffTags(leffffile):\n",
    "    lexicondf = pd.read_csv(leffffile, sep=\"\\t\", quoting=3, error_bad_lines=False)\n",
    "    lexicontags = {}\n",
    "    for index, row in lexicondf.iterrows():\n",
    "        token = row[\"!\"]\n",
    "        tag = row[\"PUNCT\"]\n",
    "        if(not (token in lexicontags)):\n",
    "            lexicontags[token] = tag\n",
    "        elif(not (tag in lexicontags[token])):\n",
    "            lexicontags[token] = lexicontags[token] + \"|\" + tag\n",
    "    return lexicontags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lefffTags = buildLefffTags(leffffile)\n",
    "lefffTags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Generate text dataset, statistics, dictionaries from websites extraction directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Load the extracted text files in an efficient DataFrame for each website"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following class can be used to **parse and load the .nlp.txt text files extracted from a website in a DataFrame**.\n",
    "\n",
    "See the following page for a **description of the nlptextdoc format** : https://github.com/laurentprudhon/nlptextdoc/blob/master/README.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "\n",
    "class NLPTextDocumentReader:\n",
    "    \"\"\"Read output files of a website extraction in pandas DataFrames.\n",
    "    \n",
    "    Sample usage :\n",
    "    \n",
    "    textreader = NLPTextDocumentReader(websitedir)\n",
    "    textdf = textreader.load_dataframe()\n",
    "    \"\"\"    \n",
    "    def __init__(self, websitedir):\n",
    "        self.websitedir = websitedir\n",
    "        \n",
    "        self.documentCount = 0 \n",
    "        self.nestingLevel = 1\n",
    "        self.listType = []\n",
    "        self.listCmd = []\n",
    "        self.listLevel = []\n",
    "        self.listText = []\n",
    "                \n",
    "        self.DOCUMENT_ELEMENT_LINE_MARKER = \"##\"\n",
    "        self.DOCUMENT_ELEMENT_START = \"Start\"\n",
    "        self.DOCUMENT_ELEMENT_END = \"End\"\n",
    "        self.DOCUMENT_ELEMENT_ITEMS = \"Items\"\n",
    "        self.DOCUMENT_ELEMENT_ITEMS_START = \">>\"\n",
    "        self.DOCUMENT_ELEMENT_ITEMS_SEPARATOR = \"||\"\n",
    "        \n",
    "        self.TEXT_DOCUMENT_PROPERTY_PREFIX = self.DOCUMENT_ELEMENT_LINE_MARKER + \" NLPTextDocument \"\n",
    "        self.TEXT_DOCUMENT_TITLE = \"Title\"\n",
    "        self.TEXT_DOCUMENT_URI = \"Uri\"\n",
    "        \n",
    "        self.DOCUMENT_ELEMENT_LINE_REGEX = re.compile(\n",
    "            self.DOCUMENT_ELEMENT_LINE_MARKER + \" \"\n",
    "            + \"(?P<NestingLevel>[0-9]+)\" + \" \"\n",
    "            + \"(?P<ElementName>[A-Za-z]+)\" + \" \"\n",
    "            + \"(?P<Command>\" + self.DOCUMENT_ELEMENT_START + \"|\" + self.DOCUMENT_ELEMENT_END + \"|\" + self.DOCUMENT_ELEMENT_ITEMS + \")\" + \" ?\")\n",
    "        \n",
    "    def load_dataframe(self):\n",
    "        textdffile = self.websitedir / \"nlptextdocs.dataframe.feather\"\n",
    "        if(textdffile.exists()):\n",
    "            return pd.read_feather(textdffile)\n",
    "        else:\n",
    "            for textfile in self.websitedir.glob(\"**/*.nlp.txt\"):\n",
    "                with textfile.open(mode=\"r\", encoding=\"utf-8-sig\") as f:   \n",
    "                    self.textfile = textfile\n",
    "                    self.documentCount = self.documentCount+1\n",
    "                    self.onDocumentStart(str(self.documentCount))\n",
    "                    self.isreadingproperties = True\n",
    "                    for lineidx,line in enumerate(f):\n",
    "                        line = line.strip()\n",
    "                        if(not line): continue\n",
    "                        self.lineidx = lineidx\n",
    "                        self.readline(line)\n",
    "                    self.onDocumentEnd(str(self.documentCount))\n",
    "            textdf = pd.DataFrame({\"DocEltType\": self.listType, \"DocEltCmd\" : self.listCmd, \"NestingLevel\": self.listLevel, \"Text\":self.listText})\n",
    "            textdf = textdf.astype({\"DocEltType\": \"category\", \"DocEltCmd\": \"category\", \"NestingLevel\": np.uint8},copy=False)\n",
    "            self.__init__(self.websitedir)\n",
    "            textdf.to_feather(textdffile)\n",
    "            return textdf\n",
    "\n",
    "    def readline(self,line):\n",
    "        if (self.isreadingproperties):\n",
    "            if (line.startswith(self.TEXT_DOCUMENT_PROPERTY_PREFIX)):\n",
    "                self.readproperty(line[len(self.TEXT_DOCUMENT_PROPERTY_PREFIX):])\n",
    "            else:\n",
    "                self.isreadingproperties = False\n",
    "        if (not self.isreadingproperties):\n",
    "            self.readelement(line)\n",
    "                \n",
    "    def readproperty(self,propstr):\n",
    "        firstspaceindex = propstr.find(\" \");\n",
    "        if (firstspaceindex > 0):\n",
    "            propertyname = propstr[:firstspaceindex]            \n",
    "            propertyvalue = propstr[firstspaceindex + 1:].strip()\n",
    "            if(propertyname == self.TEXT_DOCUMENT_TITLE):\n",
    "                self.onDocumentTitle(propertyvalue)\n",
    "            elif(propertyname == self.TEXT_DOCUMENT_URI):\n",
    "                self.onDocumentUri(propertyvalue)       \n",
    "    \n",
    "    def readelement(self,line):\n",
    "        if (line.startswith(self.DOCUMENT_ELEMENT_LINE_MARKER)):\n",
    "            self.readcommand(line)\n",
    "        else:\n",
    "            self.onTextBlock(line)\n",
    "    \n",
    "    def readcommand(self,line):\n",
    "        match = self.DOCUMENT_ELEMENT_LINE_REGEX.match(line)\n",
    "        if(match): \n",
    "            self.nestingLevel = int(match.group(\"NestingLevel\"))\n",
    "            elementName = match.group(\"ElementName\")\n",
    "            command = match.group(\"Command\")\n",
    "            if (command == self.DOCUMENT_ELEMENT_START):\n",
    "                title = line[match.end():].strip()\n",
    "                if (len(title) == 0): title = None\n",
    "                if(elementName == \"Section\"):\n",
    "                    self.onSectionStart(title)\n",
    "                elif(elementName == \"NavigationList\"):\n",
    "                    self.onNavigationListStart(title)\n",
    "                elif(elementName == \"List\"):\n",
    "                    self.onListStart(title)\n",
    "                elif(elementName == \"ListItem\"):\n",
    "                    self.onListItemStart()\n",
    "                elif(elementName == \"Table\"):\n",
    "                    self.onTableStart(title)\n",
    "                elif(elementName == \"TableHeader\"):\n",
    "                    self.onTableHeaderStart()           \n",
    "                elif(elementName == \"TableCell\"):\n",
    "                    self.onTableCellStart()\n",
    "            elif (command == self.DOCUMENT_ELEMENT_END):\n",
    "                if(elementName == \"Section\"):\n",
    "                    self.onSectionEnd()\n",
    "                elif(elementName == \"NavigationList\"):\n",
    "                    self.onNavigationListEnd()\n",
    "                elif(elementName == \"List\"):\n",
    "                    self.onListEnd()\n",
    "                elif(elementName == \"ListItem\"):\n",
    "                    self.onListItemEnd()\n",
    "                elif(elementName == \"Table\"):\n",
    "                    self.onTableEnd()\n",
    "                elif(elementName == \"TableHeader\"):\n",
    "                    self.onTableHeaderEnd()                 \n",
    "                elif(elementName == \"TableCell\"):\n",
    "                    self.onTableCellEnd()\n",
    "            elif (command == self.DOCUMENT_ELEMENT_ITEMS):\n",
    "                startOfItems = line.find(self.DOCUMENT_ELEMENT_ITEMS_START)\n",
    "                title = line[match.end():startOfItems].strip()\n",
    "                if (len(title) == 0): title = None\n",
    "                if (elementName == \"NavigationList\"):\n",
    "                    self.onNavigationListStart(title)\n",
    "                elif (elementName == \"List\"):\n",
    "                    self.onListStart(title)             \n",
    "                self.nestingLevel = self.nestingLevel+1\n",
    "                items = line[startOfItems+len(self.DOCUMENT_ELEMENT_ITEMS_START):].split(self.DOCUMENT_ELEMENT_ITEMS_SEPARATOR)\n",
    "                for item in items:\n",
    "                    item = item.strip()\n",
    "                    if (len(item) > 0):\n",
    "                        self.onInlineListItem(item)\n",
    "                self.nestingLevel = self.nestingLevel-1\n",
    "                if (elementName == \"NavigationList\"):\n",
    "                    self.onNavigationListEnd()\n",
    "                elif (elementName == \"List\"):\n",
    "                    self.onListEnd()\n",
    "            else:\n",
    "                raise Exception(f\"File format error in file {self.textfile} on line {self.lineidx} : {line[:min(len(line), 50)]}\");                     \n",
    "        else:\n",
    "            raise Exception(f\"File format error in file {self.textfile} on line {self.lineidx} : {line[:min(len(line), 50)]}\");\n",
    "    \n",
    "    def onDocumentStart(self,docId):\n",
    "        self.appendrow(\"Document\",\"Start\",docId)\n",
    "    \n",
    "    def onDocumentTitle(self,title):\n",
    "        self.appendrow(\"Document\",\"Title\",title)\n",
    "            \n",
    "    def onDocumentUri(self,uri):\n",
    "        self.appendrow(\"Document\",\"Uri\",uri)\n",
    "    \n",
    "    def onDocumentEnd(self,docId):\n",
    "        self.appendrow(\"Document\",\"End\",docId)\n",
    "    \n",
    "    def onTextBlock(self,text):\n",
    "        self.appendrow(\"TextBlock\",\"Text\",text)\n",
    "            \n",
    "    def onSectionStart(self,title):\n",
    "        self.appendrow(\"Section\",\"Start\",title)\n",
    "        \n",
    "    def onSectionEnd(self): \n",
    "        self.appendrow(\"Section\",\"End\")\n",
    "        \n",
    "    def onNavigationListStart(self,title):\n",
    "        self.appendrow(\"NavigationList\",\"Start\",title)\n",
    "        \n",
    "    def onNavigationListEnd(self):\n",
    "        self.appendrow(\"NavigationList\",\"End\")\n",
    "        \n",
    "    def onListStart(self,title):\n",
    "        self.appendrow(\"List\",\"Start\",title)\n",
    "        \n",
    "    def onListEnd(self):\n",
    "        self.appendrow(\"List\",\"End\")\n",
    "        \n",
    "    def onInlineListItem(self,item):\n",
    "        self.appendrow(\"ListItem\",\"Text\",item)\n",
    "            \n",
    "    def onListItemStart(self):\n",
    "        self.appendrow(\"ListItem\",\"Start\")\n",
    "        \n",
    "    def onListItemEnd(self):\n",
    "        self.appendrow(\"ListItem\",\"End\")\n",
    "        \n",
    "    def onTableStart(self,title):\n",
    "        self.appendrow(\"Table\",\"Start\",title)\n",
    "    \n",
    "    def onTableEnd(self):\n",
    "        self.appendrow(\"Table\",\"End\")\n",
    "        \n",
    "    def onTableHeaderStart(self):\n",
    "        self.appendrow(\"TableHeader\",\"Start\")\n",
    "        \n",
    "    def onTableHeaderEnd(self): \n",
    "        self.appendrow(\"TableHeader\",\"End\")\n",
    "        \n",
    "    def onTableCellStart(self):\n",
    "        self.appendrow(\"TableCell\",\"Start\")\n",
    "        \n",
    "    def onTableCellEnd(self): \n",
    "        self.appendrow(\"TableCell\",\"End\")\n",
    "            \n",
    "    def appendrow(self,docEltType,docEltCmd,text=None):\n",
    "        self.listType.append(docEltType)\n",
    "        self.listCmd.append(docEltCmd)\n",
    "        self.listLevel.append(self.nestingLevel)\n",
    "        if(text != None):\n",
    "            text = text.replace(\"\\\\n\",\"\\n\")\n",
    "        self.listText.append(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the function below to prepare DataFrames for all the extracted websites at once :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareDataFramesForWebsites(rootdir, websites):\n",
    "    \"\"\"Loads all individual text blocks extracted from the pages of each website in a dataframe, and save them efficiently on disk.\n",
    "\n",
    "    Parameters:\n",
    "    rootdir - Path to the directory where the websites were extracted\n",
    "    websites - List of strings with the websites root URLs\n",
    "    \"\"\"\n",
    "    for websiteurl in websites:\n",
    "        website = getWebsiteName(websiteurl)\n",
    "        print(f\"Preparing dataframe for website {website} ...\")        \n",
    "        websitedir = getWebsiteDir(rootdir,website)\n",
    "        reader = NLPTextDocumentReader(websitedir)\n",
    "        textdf = reader.load_dataframe()\n",
    "        docsCount = len(textdf[(textdf[\"DocEltType\"]==\"Document\") & (textdf[\"DocEltCmd\"]==\"Start\")])\n",
    "        logsdf = loadExtractionLogs(websitedir)\n",
    "        print(f\"- {len(logsdf)} website extraction logs\")\n",
    "        print(f\"- {docsCount} documents\")\n",
    "        print(f\"- {len(textdf)} document elements\")\n",
    "        print(f\"- dataframe size in memory : {_format_size_mb(_memory_size(textdf))} MB\")\n",
    "        websitefile = websitedir / \"nlptextdocs.dataframe.feather\"\n",
    "        print(f\"- dataframe size on disk : {_format_size_mb(_file_size(websitefile))} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepareDataFramesForWebsites(rootdir, websites)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you encounter a parsing error in any of the text files : just delete the corrupted file and relaunch the function above.\n",
    "\n",
    "It will run very efficiently for all the websites already processed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Filter and aggregate all interesting text blocks in a single DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While we filter and aggregate all the interesting text blocks in a single DataFrame, we also generate the following summaries of the text data for later use :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Information about the character set used in the extracted dataset :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unicodedata import name as unicodename\n",
    "\n",
    "def charname(char):\n",
    "    return unicodename(char,f\"CHAR {ord(char)}\")\n",
    "\n",
    "def saveCharset(rootdir, vocabdf):\n",
    "    print(\"Saving the character set ...\")\n",
    "    charcounts = defaultdict(lambda:0)\n",
    "    for idx,row in vocabdf.iterrows():\n",
    "        token = row[\"Word\"]\n",
    "        count = row[\"Count\"]\n",
    "        for char in token:\n",
    "            charcode = ord(char)\n",
    "            charcounts[charcode] = charcounts[charcode] + count\n",
    "    charsetdf = pd.DataFrame({\"Code\" : [*charcounts.keys()], \"Count\" : [*charcounts.values()]})\n",
    "    charsetdf.sort_values(\"Count\", ascending=False, inplace=True)\n",
    "    charsetdf.reset_index(inplace=True)\n",
    "    charsetdf.drop('index', axis=1, inplace=True)\n",
    "    charsetdf[\"Char\"] = charsetdf[\"Code\"].map(lambda x:chr(x))\n",
    "    charsetdf[\"CharName\"] = charsetdf[\"Char\"].map(lambda c:charname(c))\n",
    "    charsetdf[\"isAlpha\"] = charsetdf[\"Char\"].map(lambda x:x.isalpha())\n",
    "    charsetdf[\"isDigit\"] = charsetdf[\"Char\"].map(lambda x:x.isdigit())\n",
    "    charsetdf[\"isSpace\"] = charsetdf[\"Char\"].map(lambda x:x.isspace())\n",
    "    charsetdf[\"Percent\"] = 100*charsetdf[\"Count\"].cumsum()/charsetdf[\"Count\"].sum()\n",
    "    charsetfile = rootdir / \"charset.dataframe.feather\"\n",
    "    charsetdf.to_feather(charsetfile)\n",
    "    charsetdf.to_csv(rootdir / \"charset.csv\",sep=\";\")\n",
    "    print(f\"- {len(charsetdf)} distinct characters\")\n",
    "    return charsetdf\n",
    "               \n",
    "def loadCharset(rootdir):\n",
    "    charsetfile = rootdir / \"charset.dataframe.feather\"\n",
    "    return pd.read_feather(charsetfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Information about the vocabulary (distinct words) used in the extracted dataset :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveVocabulary(rootdir, vocabdict):\n",
    "    print(\"Saving the vocabulary ...\")\n",
    "    vocabdf = pd.DataFrame({\"Word\" : [*vocabdict.keys()], \"Count\" : [*vocabdict.values()]})\t\n",
    "    vocabdf.sort_values(\"Count\", ascending=False, inplace=True)\n",
    "    vocabdf.reset_index(inplace=True)    \n",
    "    vocabdf.drop('index', axis=1, inplace=True)\n",
    "    vocabdf[\"LefffTags\"] = vocabdf[\"Word\"].apply(lambda word: _getTokenTags(str(word),lefffTags))\n",
    "    vocabdf[\"DicollecteTags\"] = vocabdf[\"Word\"].apply(lambda word: _getTokenTags(str(word),dicollecteTags))\n",
    "    vocabdf[\"CommonTags\"] = vocabdf.apply(lambda row: _mergeTokenTags(str(row[\"LefffTags\"]),str(row[\"DicollecteTags\"])),axis=1)\n",
    "    vocabdf[\"Percent\"] = 100*vocabdf[\"Count\"].cumsum()/vocabdf[\"Count\"].sum()\n",
    "    vocabfile = rootdir / \"vocabulary.dataframe.feather\"\n",
    "    vocabdf.to_feather(vocabfile)\n",
    "    vocabdf.to_csv(rootdir / \"vocabulary.csv\",sep=\";\")\n",
    "    print(f\"- {len(vocabdf)} distinct words\")\n",
    "    return vocabdf\n",
    "\n",
    "def _getTokenTags(token,tags):\n",
    "    annot = tags.get(token)\n",
    "    if(annot is None):\n",
    "        annot = tags.get(token.lower())\n",
    "    if(annot is None):\n",
    "        try:\n",
    "            float(token.replace(\",\",\".\"))\n",
    "        except ValueError:\n",
    "            return None\n",
    "        return \"Number\"\n",
    "    return annot\n",
    "\n",
    "def _mergeTokenTags(annot1,annot2):\n",
    "    if(annot1 == annot2):\n",
    "        return annot1\n",
    "    elif((annot1 != \"None\") and (annot2 == \"None\")):\n",
    "        return annot1\n",
    "    elif((annot1 == \"None\") and (annot2 != \"None\")):\n",
    "        return annot2\n",
    "    else:\n",
    "        tags1 = set(annot1.split(\"|\"))\n",
    "        tags2 = set(annot2.split(\"|\"))\n",
    "        mergedtags = tags1 | tags2\n",
    "        return \"|\".join(mergedtags)\n",
    "    \n",
    "def loadVocabulary(rootdir):\n",
    "    vocabfile = rootdir / \"vocabulary.dataframe.feather\"\n",
    "    return pd.read_feather(vocabfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine all textblocks from each website in a single dataframe, while applying several filters to enhance the dataset quality:\n",
    "- keep only distinct text blocks for each website\n",
    "- keep only text blocks with more than 5 words\n",
    "- keep only text blocks in french "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from hashlib import md5\n",
    "\n",
    "def createDatasetFromWebsites(rootdir, websites, minWordsCount=5, filterLanguage=\"fr\"):\n",
    "    \"\"\"Combine all textblocks from each website in a single dataframe, while applying several filters to enhance the dataset quality:\n",
    "    - keep only distinct text blocks for each website\n",
    "    - keep only text blocks with more than 5 words\n",
    "    - keep only text blocks in french\n",
    "\n",
    "    Create at the same time 4 additional dataframes:\n",
    "    - a dictionary of all distinct words encountered in the dataset by decreasing frequency\n",
    "    - a dictionary of all distinct characters encountered in the dataset by decreasing frequency\n",
    "    - a table of the dataset statistics\n",
    "\n",
    "    Parameters:\n",
    "    rootdir - Path to the directory where the websites were extracted\n",
    "    websites - List of strings with the websites root URLs\n",
    "    \"\"\"\n",
    "    charsCount = 0\n",
    "    wordsCount = 0\n",
    "    vocabdict = defaultdict(lambda:0)\n",
    "    listSiteIndex = []\n",
    "    listRowIndex = []\n",
    "    listText = []\n",
    "    listWordCounts = []    \n",
    "    listWebsites = []\n",
    "    listWebsitesWordCounts = []\n",
    "    nlp = spacy_InitWithTokenizerAndLanguageDetector()\n",
    "    for idx,websiteUrl in enumerate(websites):\n",
    "        website = getWebsiteName(websiteUrl)\n",
    "        websitedir = getWebsiteDir(rootdir,website)\n",
    "        hashes = set()\n",
    "        print(f\"Loading dataframe for website {website} ...\")\n",
    "        reader = NLPTextDocumentReader(websitedir)\n",
    "        textdf = reader.load_dataframe()\n",
    "        print(f\"- filtering and tokenizing {len(textdf)} text blocks ...\")\n",
    "        websitetexts = textdf[((textdf[\"DocEltType\"] != \"Document\") | (textdf[\"DocEltCmd\"] == \"Title\")) & (textdf[\"DocEltCmd\"] != \"End\") & ~textdf[\"Text\"].isnull()][\"Text\"]\n",
    "        localWordsCount = 0\n",
    "        for rowidx,text in websitetexts.iteritems():\n",
    "            hval = md5(text.encode()).digest()\n",
    "            if not (hval in hashes):         \n",
    "                hashes.add(hval)\n",
    "                doc = nlp(text)\n",
    "                rowWordsCount = len(doc)\n",
    "                rowLanguage = spacy_DetectLanguage(doc)\n",
    "                if (rowWordsCount >= minWordsCount) and (rowLanguage == filterLanguage):\n",
    "                    charsCount = charsCount + len(text)\n",
    "                    localWordsCount = localWordsCount + rowWordsCount\n",
    "                    for token in doc:\n",
    "                        vocabdict[token.text] = vocabdict[token.text] + 1\n",
    "                    listSiteIndex.append(idx)\n",
    "                    listRowIndex.append(rowidx)\n",
    "                    listText.append(text)\n",
    "                    listWordCounts.append(rowWordsCount)\n",
    "        listWebsites.append(website)\n",
    "        listWebsitesWordCounts.append(localWordsCount)\n",
    "        print(f\"- this website contributed {localWordsCount} words to the dataset\")\n",
    "        wordsCount = wordsCount + localWordsCount\n",
    "\n",
    "    print(\"Saving the complete dataset ...\")\n",
    "    datasetdf = pd.DataFrame({\"SiteIndex\": listSiteIndex, \"RowIndex\" : listRowIndex, \"Text\":listText, \"WordsCount\":listWordCounts})\n",
    "    print(f\"- {charsCount} characters, {wordsCount} words, {len(datasetdf)} text blocks\")\n",
    "    print(f\"- dataset size in memory : {_format_size_mb(_memory_size(datasetdf))} MB\")\n",
    "    datasetfile = rootdir / \"dataset.dataframe.feather\"\n",
    "    datasetdf.to_feather(datasetfile)\n",
    "    print(f\"- dataset size on disk : {_format_size_mb(_file_size(datasetfile))} MB\")\n",
    "    \n",
    "    vocabdf = saveVocabulary(rootdir, vocabdict)\n",
    "    charsetdf = saveCharset(rootdir, vocabdf)\n",
    "\n",
    "    statsdf = pd.DataFrame({\"Website\": listWebsites,\"WordsCount\":listWebsitesWordCounts})    \n",
    "    statsdf[\"Percent\"] = stats[\"WordsCount\"].apply(lambda w:w/wordsCount*100)\n",
    "    statsdf.sort_values(\"Percent\",ascending=False,inplace=True)\n",
    "    statsfile = rootdir / \"stats.csv\"\n",
    "    statsdf.to_csv(statsfile)    \n",
    "    \n",
    "def loadDataset(rootdir):\n",
    "    datasetfile = rootdir / \"dataset.dataframe.feather\"\n",
    "    return pd.read_feather(datasetfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use all these functions to create our dataset : depending on the amount of data this could take SEVERAL HOURS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "createDatasetFromWebsites(rootdir,websites)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Study vocabulary and tokenizer perf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Unknown words and proper nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listUnknownWordsAndProperNouns(vocabdf):\n",
    "    uwords = vocabdf[(vocabdf[\"CommonTags\"] == \"None\") | (vocabdf[\"CommonTags\"].str.contains(\"PROPN\"))].copy()\n",
    "    uwords[\"Length\"] = uwords[\"Word\"].apply(lambda w: len(w))\n",
    "    uwords[\"isSpace\"] = uwords[\"Word\"].apply(lambda w: w.isspace())\n",
    "    uwords[\"CharName\"] = uwords[\"Word\"].apply(lambda w: charname(w) if len(w)==1 else \"\")\n",
    "    uwords.to_csv(rootdir / \"specificwords.csv\",sep=\";\")\n",
    "    return uwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\laure\\Anaconda3\\envs\\spacy\\lib\\site-packages\\pyarrow\\pandas_compat.py:752: FutureWarning: .labels was deprecated in version 0.24.0. Use .codes instead.\n",
      "  labels, = index.labels\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Count</th>\n",
       "      <th>LefffTags</th>\n",
       "      <th>DicollecteTags</th>\n",
       "      <th>CommonTags</th>\n",
       "      <th>Percent</th>\n",
       "      <th>Length</th>\n",
       "      <th>isSpace</th>\n",
       "      <th>CharName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td></td>\n",
       "      <td>52198</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>26.229810</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>NO-BREAK SPACE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>€</td>\n",
       "      <td>11834</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>43.561460</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>EURO SIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>…</td>\n",
       "      <td>7794</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>46.390409</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>HORIZONTAL ELLIPSIS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>!</td>\n",
       "      <td>7773</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>46.517784</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>EXCLAMATION MARK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>France</td>\n",
       "      <td>6961</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NOUN|PROPN</td>\n",
       "      <td>47.844507</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>–</td>\n",
       "      <td>3940</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>54.040798</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>EN DASH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td></td>\n",
       "      <td>3675</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>55.153670</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>SPACE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>Paris</td>\n",
       "      <td>3578</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>55.451192</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>\\n</td>\n",
       "      <td>2580</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>58.419299</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>CHAR 10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>Epargne</td>\n",
       "      <td>2443</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>58.911400</td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>ING</td>\n",
       "      <td>1830</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>62.084984</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>Internet</td>\n",
       "      <td>1781</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NOUN|PROPN</td>\n",
       "      <td>62.291607</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>•</td>\n",
       "      <td>1649</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>63.132914</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>BULLET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>Fortuneo</td>\n",
       "      <td>1646</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>63.159887</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td></td>\n",
       "      <td>1636</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>63.267271</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>PEA</td>\n",
       "      <td>1618</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>63.320414</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>Bank</td>\n",
       "      <td>1576</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>63.607825</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>Boursorama</td>\n",
       "      <td>1526</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>63.987872</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>BNP</td>\n",
       "      <td>1473</td>\n",
       "      <td>None</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>64.456162</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>SCPI</td>\n",
       "      <td>1469</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>64.504356</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>BforBank</td>\n",
       "      <td>1384</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>65.252700</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>Paribas</td>\n",
       "      <td>1329</td>\n",
       "      <td>None</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>65.675697</td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>Europe</td>\n",
       "      <td>1314</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NOUN|PROPN</td>\n",
       "      <td>65.848760</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>602</th>\n",
       "      <td>Monabanq</td>\n",
       "      <td>1090</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>67.993897</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>Orange</td>\n",
       "      <td>1062</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>68.293762</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>627</th>\n",
       "      <td>MMA</td>\n",
       "      <td>1043</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>68.431527</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>654</th>\n",
       "      <td>’</td>\n",
       "      <td>1008</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>68.885463</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>RIGHT SINGLE QUOTATION MARK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>665</th>\n",
       "      <td>LCL</td>\n",
       "      <td>988</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>69.064671</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>701</th>\n",
       "      <td>Aviva</td>\n",
       "      <td>937</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>VERB</td>\n",
       "      <td>PROPN|VERB</td>\n",
       "      <td>69.630759</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>708</th>\n",
       "      <td></td>\n",
       "      <td>933</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>69.738012</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>THIN SPACE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Word  Count LefffTags DicollecteTags  CommonTags    Percent  \\\n",
       "13               52198      None           None        None  26.229810   \n",
       "51            €  11834      None           None        None  43.561460   \n",
       "69            …   7794      None           None        None  46.390409   \n",
       "70            !   7773      None           None        None  46.517784   \n",
       "81       France   6961     PROPN           NOUN  NOUN|PROPN  47.844507   \n",
       "155           –   3940      None           None        None  54.040798   \n",
       "173               3675      None           None        None  55.153670   \n",
       "178       Paris   3578     PROPN          PROPN       PROPN  55.451192   \n",
       "239          \\n   2580      None           None        None  58.419299   \n",
       "251     Epargne   2443      None           None        None  58.911400   \n",
       "343         ING   1830      None           None        None  62.084984   \n",
       "350    Internet   1781      NOUN          PROPN  NOUN|PROPN  62.291607   \n",
       "380           •   1649      None           None        None  63.132914   \n",
       "381    Fortuneo   1646      None           None        None  63.159887   \n",
       "385               1636      None           None        None  63.267271   \n",
       "387         PEA   1618      None           None        None  63.320414   \n",
       "398        Bank   1576      None           None        None  63.607825   \n",
       "413  Boursorama   1526      None           None        None  63.987872   \n",
       "432         BNP   1473      None          PROPN       PROPN  64.456162   \n",
       "434        SCPI   1469      None           None        None  64.504356   \n",
       "466    BforBank   1384      None           None        None  65.252700   \n",
       "485     Paribas   1329      None          PROPN       PROPN  65.675697   \n",
       "493      Europe   1314     PROPN           NOUN  NOUN|PROPN  65.848760   \n",
       "602    Monabanq   1090      None           None        None  67.993897   \n",
       "619      Orange   1062     PROPN          PROPN       PROPN  68.293762   \n",
       "627         MMA   1043      None           None        None  68.431527   \n",
       "654           ’   1008      None           None        None  68.885463   \n",
       "665         LCL    988      None           None        None  69.064671   \n",
       "701       Aviva    937     PROPN           VERB  PROPN|VERB  69.630759   \n",
       "708                933      None           None        None  69.738012   \n",
       "\n",
       "     Length  isSpace                     CharName  \n",
       "13        1     True               NO-BREAK SPACE  \n",
       "51        1    False                    EURO SIGN  \n",
       "69        1    False          HORIZONTAL ELLIPSIS  \n",
       "70        1    False             EXCLAMATION MARK  \n",
       "81        6    False                               \n",
       "155       1    False                      EN DASH  \n",
       "173       1     True                        SPACE  \n",
       "178       5    False                               \n",
       "239       1     True                      CHAR 10  \n",
       "251       7    False                               \n",
       "343       3    False                               \n",
       "350       8    False                               \n",
       "380       1    False                       BULLET  \n",
       "381       8    False                               \n",
       "385       2     True                               \n",
       "387       3    False                               \n",
       "398       4    False                               \n",
       "413      10    False                               \n",
       "432       3    False                               \n",
       "434       4    False                               \n",
       "466       8    False                               \n",
       "485       7    False                               \n",
       "493       6    False                               \n",
       "602       8    False                               \n",
       "619       6    False                               \n",
       "627       3    False                               \n",
       "654       1    False  RIGHT SINGLE QUOTATION MARK  \n",
       "665       3    False                               \n",
       "701       5    False                               \n",
       "708       1     True                   THIN SPACE  "
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabdf = loadVocabulary(rootdir)\n",
    "specificwords = listUnknownWordsAndProperNouns(vocabdf)\n",
    "specificwords.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getContextAroundWord(text,word,ctxsize=20):\n",
    "    idx = text.index(word)\n",
    "    start = max(idx-ctxsize,0)\n",
    "    end = min(idx+ctxsize,len(text))\n",
    "    return text[start:end+1]\n",
    "\n",
    "def sampleTextBlocksWithChar(textdf,char,count=100,ctxsize=20):\n",
    "    textsWithWord = textdf[textdf[\"Text\"].str.contains(char,regex=False)]\n",
    "    textsWithWord = textsWithWord.sample(count)\n",
    "    textsWithWord[\"Context\"] = textsWithWord[\"Text\"].apply(lambda t: getContextAroundWord(t,char,ctxsize))\n",
    "    return textsWithWord.copy()\n",
    "\n",
    "def sampleTextBlocksWithWord(textdf,word,count=100,ctxsize=20):\n",
    "    textsWithWord = textdf[textdf[\"Text\"].str.contains(\"\\\\b\"+word+\"\\\\b\")]\n",
    "    textsWithWord = textsWithWord.sample(count)\n",
    "    textsWithWord[\"Context\"] = textsWithWord[\"Text\"].apply(lambda t: getContextAroundWord(t,word,ctxsize))\n",
    "    return textsWithWord.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\laure\\Anaconda3\\envs\\spacy\\lib\\site-packages\\pyarrow\\pandas_compat.py:752: FutureWarning: .labels was deprecated in version 0.24.0. Use .codes instead.\n",
      "  labels, = index.labels\n"
     ]
    }
   ],
   "source": [
    "dataset = loadDataset(rootdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SiteIndex</th>\n",
       "      <th>RowIndex</th>\n",
       "      <th>Text</th>\n",
       "      <th>WordsCount</th>\n",
       "      <th>Context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>78777</th>\n",
       "      <td>51</td>\n",
       "      <td>23427</td>\n",
       "      <td>Crédit Mutuel Arkéa - Nos métiers - ABEI - Pag...</td>\n",
       "      <td>12</td>\n",
       "      <td>Crédit Mutuel Arkéa - Nos mé</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205845</th>\n",
       "      <td>115</td>\n",
       "      <td>6655</td>\n",
       "      <td>Livret Bienvenue de Crédit Mutuel</td>\n",
       "      <td>5</td>\n",
       "      <td>Bienvenue de Crédit Mutuel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133173</th>\n",
       "      <td>79</td>\n",
       "      <td>5677</td>\n",
       "      <td>Mettre de l'argent de côté permet de faire fac...</td>\n",
       "      <td>47</td>\n",
       "      <td>ng terme. Au Crédit Mutuel, plusieurs sol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77897</th>\n",
       "      <td>51</td>\n",
       "      <td>4291</td>\n",
       "      <td>Jean-Pierre Denis, Président du Crédit Mutuel ...</td>\n",
       "      <td>98</td>\n",
       "      <td>Président du Crédit Mutuel Arkéa et du Cr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132852</th>\n",
       "      <td>79</td>\n",
       "      <td>2811</td>\n",
       "      <td>1 er réseau bancaire né de la volonté des Prof...</td>\n",
       "      <td>51</td>\n",
       "      <td>ur elles, le Crédit Mutuel des Profession</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42475</th>\n",
       "      <td>26</td>\n",
       "      <td>3033</td>\n",
       "      <td>En 1984, suite à une demande déposée par les a...</td>\n",
       "      <td>47</td>\n",
       "      <td>ricole et le Crédit Mutuel le Groupement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58770</th>\n",
       "      <td>38</td>\n",
       "      <td>7560</td>\n",
       "      <td>2 nouveaux contrats complètent la gamme ! mes-...</td>\n",
       "      <td>51</td>\n",
       "      <td>(filiale du Crédit Mutuel Arkéa) mes-pla</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130608</th>\n",
       "      <td>77</td>\n",
       "      <td>9913</td>\n",
       "      <td>Frais bancaires Crédit Mutuel Normandie</td>\n",
       "      <td>5</td>\n",
       "      <td>is bancaires Crédit Mutuel Normandie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78064</th>\n",
       "      <td>51</td>\n",
       "      <td>7639</td>\n",
       "      <td>Crédit Mutuel Arkéa - Présentation de la direc...</td>\n",
       "      <td>14</td>\n",
       "      <td>Crédit Mutuel Arkéa - Présen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78593</th>\n",
       "      <td>51</td>\n",
       "      <td>17742</td>\n",
       "      <td>Assurances - Crédit Mutuel Arkéa 1</td>\n",
       "      <td>6</td>\n",
       "      <td>Assurances - Crédit Mutuel Arkéa 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89205</th>\n",
       "      <td>56</td>\n",
       "      <td>14097</td>\n",
       "      <td>Gratuits dans les distributeurs Crédit Mutuel ...</td>\n",
       "      <td>8</td>\n",
       "      <td>istributeurs Crédit Mutuel et CIC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88808</th>\n",
       "      <td>56</td>\n",
       "      <td>11283</td>\n",
       "      <td>Filiale du Groupe Casino et de Crédit Mutuel-C...</td>\n",
       "      <td>26</td>\n",
       "      <td>Casino et de Crédit Mutuel-CIC, nous prop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132800</th>\n",
       "      <td>79</td>\n",
       "      <td>2404</td>\n",
       "      <td>Le Crédit Mutuel se réserve le droit de modifi...</td>\n",
       "      <td>16</td>\n",
       "      <td>Le Crédit Mutuel se réserve le</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78581</th>\n",
       "      <td>51</td>\n",
       "      <td>17438</td>\n",
       "      <td>Arkéa Banque - Crédit Mutuel Arkéa 3</td>\n",
       "      <td>7</td>\n",
       "      <td>kéa Banque - Crédit Mutuel Arkéa 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94411</th>\n",
       "      <td>60</td>\n",
       "      <td>11753</td>\n",
       "      <td>Toutefois, même si cette initiative est plutôt...</td>\n",
       "      <td>114</td>\n",
       "      <td>ualistes, du Crédit Mutuel à la Caisse d’</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132766</th>\n",
       "      <td>79</td>\n",
       "      <td>2333</td>\n",
       "      <td>Éditeur du site et des applications Crédit Mutuel</td>\n",
       "      <td>9</td>\n",
       "      <td>applications Crédit Mutuel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78413</th>\n",
       "      <td>51</td>\n",
       "      <td>13329</td>\n",
       "      <td>Crédit Mutuel Arkéa - Analystes et investisseu...</td>\n",
       "      <td>13</td>\n",
       "      <td>Crédit Mutuel Arkéa - Analys</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134956</th>\n",
       "      <td>79</td>\n",
       "      <td>22465</td>\n",
       "      <td>Marché : Professionnel | Crédit Mutuel</td>\n",
       "      <td>6</td>\n",
       "      <td>fessionnel | Crédit Mutuel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77810</th>\n",
       "      <td>51</td>\n",
       "      <td>1862</td>\n",
       "      <td>Créés en 1984 et portés jusque-là par les asso...</td>\n",
       "      <td>49</td>\n",
       "      <td>s locales du Crédit Mutuel de Bretagne (C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142268</th>\n",
       "      <td>88</td>\n",
       "      <td>4367</td>\n",
       "      <td>Tonic Croissance, compte à terme de la banque ...</td>\n",
       "      <td>28</td>\n",
       "      <td>de la banque Crédit Mutuel, placement blo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        SiteIndex  RowIndex  \\\n",
       "78777          51     23427   \n",
       "205845        115      6655   \n",
       "133173         79      5677   \n",
       "77897          51      4291   \n",
       "132852         79      2811   \n",
       "42475          26      3033   \n",
       "58770          38      7560   \n",
       "130608         77      9913   \n",
       "78064          51      7639   \n",
       "78593          51     17742   \n",
       "89205          56     14097   \n",
       "88808          56     11283   \n",
       "132800         79      2404   \n",
       "78581          51     17438   \n",
       "94411          60     11753   \n",
       "132766         79      2333   \n",
       "78413          51     13329   \n",
       "134956         79     22465   \n",
       "77810          51      1862   \n",
       "142268         88      4367   \n",
       "\n",
       "                                                     Text  WordsCount  \\\n",
       "78777   Crédit Mutuel Arkéa - Nos métiers - ABEI - Pag...          12   \n",
       "205845                  Livret Bienvenue de Crédit Mutuel           5   \n",
       "133173  Mettre de l'argent de côté permet de faire fac...          47   \n",
       "77897   Jean-Pierre Denis, Président du Crédit Mutuel ...          98   \n",
       "132852  1 er réseau bancaire né de la volonté des Prof...          51   \n",
       "42475   En 1984, suite à une demande déposée par les a...          47   \n",
       "58770   2 nouveaux contrats complètent la gamme ! mes-...          51   \n",
       "130608            Frais bancaires Crédit Mutuel Normandie           5   \n",
       "78064   Crédit Mutuel Arkéa - Présentation de la direc...          14   \n",
       "78593                  Assurances - Crédit Mutuel Arkéa 1           6   \n",
       "89205   Gratuits dans les distributeurs Crédit Mutuel ...           8   \n",
       "88808   Filiale du Groupe Casino et de Crédit Mutuel-C...          26   \n",
       "132800  Le Crédit Mutuel se réserve le droit de modifi...          16   \n",
       "78581                Arkéa Banque - Crédit Mutuel Arkéa 3           7   \n",
       "94411   Toutefois, même si cette initiative est plutôt...         114   \n",
       "132766  Éditeur du site et des applications Crédit Mutuel           9   \n",
       "78413   Crédit Mutuel Arkéa - Analystes et investisseu...          13   \n",
       "134956             Marché : Professionnel | Crédit Mutuel           6   \n",
       "77810   Créés en 1984 et portés jusque-là par les asso...          49   \n",
       "142268  Tonic Croissance, compte à terme de la banque ...          28   \n",
       "\n",
       "                                          Context  \n",
       "78777                Crédit Mutuel Arkéa - Nos mé  \n",
       "205845                 Bienvenue de Crédit Mutuel  \n",
       "133173  ng terme. Au Crédit Mutuel, plusieurs sol  \n",
       "77897   Président du Crédit Mutuel Arkéa et du Cr  \n",
       "132852  ur elles, le Crédit Mutuel des Profession  \n",
       "42475   ricole et le Crédit Mutuel le Groupement   \n",
       "58770    (filiale du Crédit Mutuel Arkéa) mes-pla  \n",
       "130608       is bancaires Crédit Mutuel Normandie  \n",
       "78064                Crédit Mutuel Arkéa - Présen  \n",
       "78593          Assurances - Crédit Mutuel Arkéa 1  \n",
       "89205           istributeurs Crédit Mutuel et CIC  \n",
       "88808   Casino et de Crédit Mutuel-CIC, nous prop  \n",
       "132800            Le Crédit Mutuel se réserve le   \n",
       "78581          kéa Banque - Crédit Mutuel Arkéa 3  \n",
       "94411   ualistes, du Crédit Mutuel à la Caisse d’  \n",
       "132766                 applications Crédit Mutuel  \n",
       "78413                Crédit Mutuel Arkéa - Analys  \n",
       "134956                 fessionnel | Crédit Mutuel  \n",
       "77810   s locales du Crédit Mutuel de Bretagne (C  \n",
       "142268  de la banque Crédit Mutuel, placement blo  "
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textsWithWord = sampleTextBlocksWithWord(dataset,\"Mutuel\")\n",
    "textsWithWord.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Most common nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listMostCommonNouns(vocabdf,count):\n",
    "    cwords = vocabdf[vocabdf[\"CommonTags\"].str.contains(\"NOUN\")]\n",
    "    cwords = cwords[:count].copy()\n",
    "    cwords.to_csv(rootdir / \"commonwords.csv\",sep=\";\")\n",
    "    return cwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Word</th>\n",
       "      <th>Count</th>\n",
       "      <th>LefffTags</th>\n",
       "      <th>DicollecteTags</th>\n",
       "      <th>CommonTags</th>\n",
       "      <th>Percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>la</td>\n",
       "      <td>109538</td>\n",
       "      <td>PRON|NOUN|DET</td>\n",
       "      <td>DET|PRON|NOUN</td>\n",
       "      <td>NOUN|DET|PRON</td>\n",
       "      <td>15.034524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>183</td>\n",
       "      <td>un</td>\n",
       "      <td>66670</td>\n",
       "      <td>DET|NOUN|PRON|NUM</td>\n",
       "      <td>DET|NOUN</td>\n",
       "      <td>NOUN|DET|PRON|NUM</td>\n",
       "      <td>23.454135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>42</td>\n",
       "      <td>pour</td>\n",
       "      <td>49910</td>\n",
       "      <td>NOUN|ADP</td>\n",
       "      <td>ADP</td>\n",
       "      <td>NOUN|ADP</td>\n",
       "      <td>27.900134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>40</td>\n",
       "      <td>une</td>\n",
       "      <td>48932</td>\n",
       "      <td>DET|PRON|NOUN|NUM</td>\n",
       "      <td>DET|NOUN</td>\n",
       "      <td>NOUN|DET|PRON|NUM</td>\n",
       "      <td>29.518757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>64</td>\n",
       "      <td>est</td>\n",
       "      <td>45859</td>\n",
       "      <td>ADJ|NOUN|AUX|VERB</td>\n",
       "      <td>NOUN|AUX</td>\n",
       "      <td>NOUN|ADJ|AUX|VERB</td>\n",
       "      <td>30.270247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>61</td>\n",
       "      <td>par</td>\n",
       "      <td>35796</td>\n",
       "      <td>NOUN|ADP</td>\n",
       "      <td>ADP</td>\n",
       "      <td>NOUN|ADP</td>\n",
       "      <td>36.230518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>256</td>\n",
       "      <td>dans</td>\n",
       "      <td>28412</td>\n",
       "      <td>ADP</td>\n",
       "      <td>ADP|NOUN</td>\n",
       "      <td>NOUN|ADP</td>\n",
       "      <td>37.749787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>91</td>\n",
       "      <td>plus</td>\n",
       "      <td>21789</td>\n",
       "      <td>VERB|ADV|CCONJ|NOUN</td>\n",
       "      <td>ADV|NOUN|VERB</td>\n",
       "      <td>NOUN|ADV|CCONJ|VERB</td>\n",
       "      <td>38.510470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2681</td>\n",
       "      <td>assurance</td>\n",
       "      <td>18147</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>40.125341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>176</td>\n",
       "      <td>%</td>\n",
       "      <td>16426</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>None</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>41.250995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>9</td>\n",
       "      <td>La</td>\n",
       "      <td>16296</td>\n",
       "      <td>PRON|NOUN|DET</td>\n",
       "      <td>DET|PRON|NOUN</td>\n",
       "      <td>NOUN|DET|PRON</td>\n",
       "      <td>41.518037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>297</td>\n",
       "      <td>pas</td>\n",
       "      <td>16090</td>\n",
       "      <td>ADV|NOUN</td>\n",
       "      <td>ADV|NOUN</td>\n",
       "      <td>ADV|NOUN</td>\n",
       "      <td>41.781703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>150</td>\n",
       "      <td>a</td>\n",
       "      <td>15867</td>\n",
       "      <td>AUX|VERB</td>\n",
       "      <td>NOUN|AUX</td>\n",
       "      <td>NOUN|AUX|VERB</td>\n",
       "      <td>42.041715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>890</td>\n",
       "      <td>compte</td>\n",
       "      <td>14152</td>\n",
       "      <td>NOUN|VERB</td>\n",
       "      <td>NOUN|VERB</td>\n",
       "      <td>NOUN|VERB</td>\n",
       "      <td>42.524295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>95</td>\n",
       "      <td>son</td>\n",
       "      <td>13306</td>\n",
       "      <td>DET|NOUN</td>\n",
       "      <td>DET|NOUN</td>\n",
       "      <td>DET|NOUN</td>\n",
       "      <td>42.742340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>1021</td>\n",
       "      <td>ligne</td>\n",
       "      <td>10816</td>\n",
       "      <td>NOUN|VERB</td>\n",
       "      <td>NOUN|VERB</td>\n",
       "      <td>NOUN|VERB</td>\n",
       "      <td>44.291876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>819</td>\n",
       "      <td>être</td>\n",
       "      <td>10265</td>\n",
       "      <td>AUX|NOUN|VERB</td>\n",
       "      <td>AUX|NOUN</td>\n",
       "      <td>NOUN|AUX|VERB</td>\n",
       "      <td>44.460089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>290</td>\n",
       "      <td>cas</td>\n",
       "      <td>9904</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>44.785993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>4063</td>\n",
       "      <td>contrat</td>\n",
       "      <td>9787</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>44.946372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>1964</td>\n",
       "      <td>crédit</td>\n",
       "      <td>9375</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>45.256463</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index       Word   Count            LefffTags DicollecteTags  \\\n",
       "4       2         la  109538        PRON|NOUN|DET  DET|PRON|NOUN   \n",
       "10    183         un   66670    DET|NOUN|PRON|NUM       DET|NOUN   \n",
       "15     42       pour   49910             NOUN|ADP            ADP   \n",
       "17     40        une   48932    DET|PRON|NOUN|NUM       DET|NOUN   \n",
       "18     64        est   45859    ADJ|NOUN|AUX|VERB       NOUN|AUX   \n",
       "27     61        par   35796             NOUN|ADP            ADP   \n",
       "30    256       dans   28412                  ADP       ADP|NOUN   \n",
       "32     91       plus   21789  VERB|ADV|CCONJ|NOUN  ADV|NOUN|VERB   \n",
       "37   2681  assurance   18147                 NOUN           NOUN   \n",
       "41    176          %   16426                 NOUN           None   \n",
       "42      9         La   16296        PRON|NOUN|DET  DET|PRON|NOUN   \n",
       "43    297        pas   16090             ADV|NOUN       ADV|NOUN   \n",
       "44    150          a   15867             AUX|VERB       NOUN|AUX   \n",
       "46    890     compte   14152            NOUN|VERB      NOUN|VERB   \n",
       "47     95        son   13306             DET|NOUN       DET|NOUN   \n",
       "55   1021      ligne   10816            NOUN|VERB      NOUN|VERB   \n",
       "56    819       être   10265        AUX|NOUN|VERB       AUX|NOUN   \n",
       "58    290        cas    9904                 NOUN           NOUN   \n",
       "59   4063    contrat    9787                 NOUN           NOUN   \n",
       "61   1964     crédit    9375                 NOUN           NOUN   \n",
       "\n",
       "             CommonTags    Percent  \n",
       "4         NOUN|DET|PRON  15.034524  \n",
       "10    NOUN|DET|PRON|NUM  23.454135  \n",
       "15             NOUN|ADP  27.900134  \n",
       "17    NOUN|DET|PRON|NUM  29.518757  \n",
       "18    NOUN|ADJ|AUX|VERB  30.270247  \n",
       "27             NOUN|ADP  36.230518  \n",
       "30             NOUN|ADP  37.749787  \n",
       "32  NOUN|ADV|CCONJ|VERB  38.510470  \n",
       "37                 NOUN  40.125341  \n",
       "41                 NOUN  41.250995  \n",
       "42        NOUN|DET|PRON  41.518037  \n",
       "43             ADV|NOUN  41.781703  \n",
       "44        NOUN|AUX|VERB  42.041715  \n",
       "46            NOUN|VERB  42.524295  \n",
       "47             DET|NOUN  42.742340  \n",
       "55            NOUN|VERB  44.291876  \n",
       "56        NOUN|AUX|VERB  44.460089  \n",
       "58                 NOUN  44.785993  \n",
       "59                 NOUN  44.946372  \n",
       "61                 NOUN  45.256463  "
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nouns = listMostCommonNouns(vocabdf,5000)\n",
    "nouns.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SiteIndex</th>\n",
       "      <th>RowIndex</th>\n",
       "      <th>Text</th>\n",
       "      <th>WordsCount</th>\n",
       "      <th>Context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>93995</th>\n",
       "      <td>60</td>\n",
       "      <td>9623</td>\n",
       "      <td>La gamme d’épargne de Boursorama Banque n’est ...</td>\n",
       "      <td>50</td>\n",
       "      <td>t A, LDD, PEL, CEL, compte sur livret et</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35560</th>\n",
       "      <td>22</td>\n",
       "      <td>15286</td>\n",
       "      <td>Si vous le souhaitez, l ' agence bancaire qui ...</td>\n",
       "      <td>68</td>\n",
       "      <td>e de vous ouvrir un compte vous fait remp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43995</th>\n",
       "      <td>26</td>\n",
       "      <td>6892</td>\n",
       "      <td>Une autre menace dont il faut tenir compte con...</td>\n",
       "      <td>51</td>\n",
       "      <td>dont il faut tenir compte concerne cette</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85478</th>\n",
       "      <td>54</td>\n",
       "      <td>9201</td>\n",
       "      <td>L’heure des résultats et de la délivrance est ...</td>\n",
       "      <td>101</td>\n",
       "      <td>emière ouverture de compte incluant une c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108570</th>\n",
       "      <td>67</td>\n",
       "      <td>4777</td>\n",
       "      <td>La fidélité compte, nous la reconnaissons.</td>\n",
       "      <td>8</td>\n",
       "      <td>La fidélité compte, nous la recon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144570</th>\n",
       "      <td>88</td>\n",
       "      <td>69272</td>\n",
       "      <td>Comparatif des rendements des OPCI. Ces placem...</td>\n",
       "      <td>101</td>\n",
       "      <td>u en direct, via un compte-titres, ou via</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130391</th>\n",
       "      <td>77</td>\n",
       "      <td>9111</td>\n",
       "      <td>Si la banque du Crédit Mutuel ( où le compte d...</td>\n",
       "      <td>104</td>\n",
       "      <td>édit Mutuel ( où le compte de cette dame</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112199</th>\n",
       "      <td>70</td>\n",
       "      <td>12258</td>\n",
       "      <td>Pour ouvrir un compte bancaire en ligne chez M...</td>\n",
       "      <td>90</td>\n",
       "      <td>Pour ouvrir un compte bancaire en li</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149630</th>\n",
       "      <td>91</td>\n",
       "      <td>24</td>\n",
       "      <td>« Quelles sont les conditions pour ouvrir un c...</td>\n",
       "      <td>14</td>\n",
       "      <td>ions pour ouvrir un compte bancaire ? »</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111879</th>\n",
       "      <td>70</td>\n",
       "      <td>8552</td>\n",
       "      <td>« Tout va bien quand il n'y a pas de problème ...</td>\n",
       "      <td>24</td>\n",
       "      <td>de problème sur le compte. J'ai un compt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92766</th>\n",
       "      <td>60</td>\n",
       "      <td>5545</td>\n",
       "      <td>Avec la souscription à l’offre EKO by CA, le n...</td>\n",
       "      <td>108</td>\n",
       "      <td>ise surprise de son compte grâce notammen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99104</th>\n",
       "      <td>61</td>\n",
       "      <td>5358</td>\n",
       "      <td>Ce type de contrat est en déclin car il expose...</td>\n",
       "      <td>59</td>\n",
       "      <td>pports en unités de compte, au travers de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35666</th>\n",
       "      <td>22</td>\n",
       "      <td>32903</td>\n",
       "      <td>Le specialiste : pour un appui technique - Mon...</td>\n",
       "      <td>19</td>\n",
       "      <td>pui technique - Mon compte bancaire - Les</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51050</th>\n",
       "      <td>29</td>\n",
       "      <td>8464</td>\n",
       "      <td>Ensuite, il vous suffit d’effectuer un premier...</td>\n",
       "      <td>57</td>\n",
       "      <td>alors ouvrir votre compte auprès de l’Ag</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20461</th>\n",
       "      <td>13</td>\n",
       "      <td>13762</td>\n",
       "      <td>Accueil &gt; Lexique des banques en ligne &gt; Arrêt...</td>\n",
       "      <td>11</td>\n",
       "      <td>n ligne &gt; Arrêté de compte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126771</th>\n",
       "      <td>76</td>\n",
       "      <td>1273</td>\n",
       "      <td>Virement occasionnel automatisable dans l’Unio...</td>\n",
       "      <td>69</td>\n",
       "      <td>is la France), d’un compte vers un autre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150037</th>\n",
       "      <td>91</td>\n",
       "      <td>6632</td>\n",
       "      <td>€ offerts pour votre première ouverture de compte</td>\n",
       "      <td>8</td>\n",
       "      <td>emière ouverture de compte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3093</th>\n",
       "      <td>2</td>\n",
       "      <td>2251</td>\n",
       "      <td>Avant d’ouvrir un compte bancaire dans un étab...</td>\n",
       "      <td>50</td>\n",
       "      <td>Avant d’ouvrir un compte bancaire dans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38026</th>\n",
       "      <td>23</td>\n",
       "      <td>9453</td>\n",
       "      <td>Selon le McKinsey Global Institute (MGI), l’or...</td>\n",
       "      <td>173</td>\n",
       "      <td>loi, même en tenant compte de l’automatis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147179</th>\n",
       "      <td>89</td>\n",
       "      <td>24841</td>\n",
       "      <td>Une réelle prise en compte de votre activité</td>\n",
       "      <td>8</td>\n",
       "      <td>Une réelle prise en compte de votre activ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        SiteIndex  RowIndex  \\\n",
       "93995          60      9623   \n",
       "35560          22     15286   \n",
       "43995          26      6892   \n",
       "85478          54      9201   \n",
       "108570         67      4777   \n",
       "144570         88     69272   \n",
       "130391         77      9111   \n",
       "112199         70     12258   \n",
       "149630         91        24   \n",
       "111879         70      8552   \n",
       "92766          60      5545   \n",
       "99104          61      5358   \n",
       "35666          22     32903   \n",
       "51050          29      8464   \n",
       "20461          13     13762   \n",
       "126771         76      1273   \n",
       "150037         91      6632   \n",
       "3093            2      2251   \n",
       "38026          23      9453   \n",
       "147179         89     24841   \n",
       "\n",
       "                                                     Text  WordsCount  \\\n",
       "93995   La gamme d’épargne de Boursorama Banque n’est ...          50   \n",
       "35560   Si vous le souhaitez, l ' agence bancaire qui ...          68   \n",
       "43995   Une autre menace dont il faut tenir compte con...          51   \n",
       "85478   L’heure des résultats et de la délivrance est ...         101   \n",
       "108570         La fidélité compte, nous la reconnaissons.           8   \n",
       "144570  Comparatif des rendements des OPCI. Ces placem...         101   \n",
       "130391  Si la banque du Crédit Mutuel ( où le compte d...         104   \n",
       "112199  Pour ouvrir un compte bancaire en ligne chez M...          90   \n",
       "149630  « Quelles sont les conditions pour ouvrir un c...          14   \n",
       "111879  « Tout va bien quand il n'y a pas de problème ...          24   \n",
       "92766   Avec la souscription à l’offre EKO by CA, le n...         108   \n",
       "99104   Ce type de contrat est en déclin car il expose...          59   \n",
       "35666   Le specialiste : pour un appui technique - Mon...          19   \n",
       "51050   Ensuite, il vous suffit d’effectuer un premier...          57   \n",
       "20461   Accueil > Lexique des banques en ligne > Arrêt...          11   \n",
       "126771  Virement occasionnel automatisable dans l’Unio...          69   \n",
       "150037  € offerts pour votre première ouverture de compte           8   \n",
       "3093    Avant d’ouvrir un compte bancaire dans un étab...          50   \n",
       "38026   Selon le McKinsey Global Institute (MGI), l’or...         173   \n",
       "147179       Une réelle prise en compte de votre activité           8   \n",
       "\n",
       "                                          Context  \n",
       "93995   t A, LDD, PEL, CEL, compte sur livret et   \n",
       "35560   e de vous ouvrir un compte vous fait remp  \n",
       "43995    dont il faut tenir compte concerne cette  \n",
       "85478   emière ouverture de compte incluant une c  \n",
       "108570          La fidélité compte, nous la recon  \n",
       "144570  u en direct, via un compte-titres, ou via  \n",
       "130391  édit Mutuel ( où le compte de cette dame   \n",
       "112199       Pour ouvrir un compte bancaire en li  \n",
       "149630    ions pour ouvrir un compte bancaire ? »  \n",
       "111879   de problème sur le compte. J'ai un compt  \n",
       "92766   ise surprise de son compte grâce notammen  \n",
       "99104   pports en unités de compte, au travers de  \n",
       "35666   pui technique - Mon compte bancaire - Les  \n",
       "51050    alors ouvrir votre compte auprès de l’Ag  \n",
       "20461                  n ligne > Arrêté de compte  \n",
       "126771  is la France), d’un compte vers un autre   \n",
       "150037                 emière ouverture de compte  \n",
       "3093      Avant d’ouvrir un compte bancaire dans   \n",
       "38026   loi, même en tenant compte de l’automatis  \n",
       "147179  Une réelle prise en compte de votre activ  "
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textsWithWord = sampleTextBlocksWithWord(dataset,\"compte\")\n",
    "textsWithWord.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Separator chars and tokenizer rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Candidate separator chars :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listSeparatorChars(charsetdf):\n",
    "    sepchars = charsetdf[(charsetdf[\"isAlpha\"] == False) & (charsetdf[\"isDigit\"] == False)].copy()\n",
    "    sepchars[\"Name\"] = sepchars[\"Char\"].apply(lambda c:c.isspace()) \n",
    "    return sepchars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Code</th>\n",
       "      <th>Count</th>\n",
       "      <th>Char</th>\n",
       "      <th>CharName</th>\n",
       "      <th>isAlpha</th>\n",
       "      <th>isDigit</th>\n",
       "      <th>isSpace</th>\n",
       "      <th>Percent</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>44</td>\n",
       "      <td>227594</td>\n",
       "      <td>,</td>\n",
       "      <td>COMMA</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>87.111540</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>46</td>\n",
       "      <td>209020</td>\n",
       "      <td>.</td>\n",
       "      <td>FULL STOP</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>88.665295</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>8217</td>\n",
       "      <td>151057</td>\n",
       "      <td>’</td>\n",
       "      <td>RIGHT SINGLE QUOTATION MARK</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>90.437958</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>39</td>\n",
       "      <td>99110</td>\n",
       "      <td>'</td>\n",
       "      <td>APOSTROPHE</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>92.088362</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>45</td>\n",
       "      <td>70047</td>\n",
       "      <td>-</td>\n",
       "      <td>HYPHEN-MINUS</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>94.560573</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>32</td>\n",
       "      <td>59143</td>\n",
       "      <td></td>\n",
       "      <td>SPACE</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>95.668293</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>160</td>\n",
       "      <td>55700</td>\n",
       "      <td></td>\n",
       "      <td>NO-BREAK SPACE</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>95.869548</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>58</td>\n",
       "      <td>55099</td>\n",
       "      <td>:</td>\n",
       "      <td>COLON</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>96.068632</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>41</td>\n",
       "      <td>42072</td>\n",
       "      <td>)</td>\n",
       "      <td>RIGHT PARENTHESIS</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>97.058604</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>40</td>\n",
       "      <td>42034</td>\n",
       "      <td>(</td>\n",
       "      <td>LEFT PARENTHESIS</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>97.210481</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>63</td>\n",
       "      <td>21147</td>\n",
       "      <td>?</td>\n",
       "      <td>QUESTION MARK</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>99.009008</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>47</td>\n",
       "      <td>21144</td>\n",
       "      <td>/</td>\n",
       "      <td>SOLIDUS</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>99.085406</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>37</td>\n",
       "      <td>16513</td>\n",
       "      <td>%</td>\n",
       "      <td>PERCENT SIGN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>99.211076</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>8364</td>\n",
       "      <td>12783</td>\n",
       "      <td>€</td>\n",
       "      <td>EURO SIGN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>99.304055</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>187</td>\n",
       "      <td>11678</td>\n",
       "      <td>»</td>\n",
       "      <td>RIGHT-POINTING DOUBLE ANGLE QUOTATION MARK</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>99.346250</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>171</td>\n",
       "      <td>11230</td>\n",
       "      <td>«</td>\n",
       "      <td>LEFT-POINTING DOUBLE ANGLE QUOTATION MARK</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>99.386826</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>34</td>\n",
       "      <td>10079</td>\n",
       "      <td>\"</td>\n",
       "      <td>QUOTATION MARK</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>99.461377</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>10</td>\n",
       "      <td>8497</td>\n",
       "      <td>\\n</td>\n",
       "      <td>CHAR 10</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>99.590831</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>33</td>\n",
       "      <td>7824</td>\n",
       "      <td>!</td>\n",
       "      <td>EXCLAMATION MARK</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>99.649122</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>8230</td>\n",
       "      <td>7816</td>\n",
       "      <td>…</td>\n",
       "      <td>HORIZONTAL ELLIPSIS</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>99.677363</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>9</td>\n",
       "      <td>5979</td>\n",
       "      <td>\\t</td>\n",
       "      <td>CHAR 9</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>99.698966</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>59</td>\n",
       "      <td>4293</td>\n",
       "      <td>;</td>\n",
       "      <td>SEMICOLON</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>99.754852</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>8211</td>\n",
       "      <td>3996</td>\n",
       "      <td>–</td>\n",
       "      <td>EN DASH</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>99.784314</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>42</td>\n",
       "      <td>3682</td>\n",
       "      <td>*</td>\n",
       "      <td>ASTERISK</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>99.811442</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>43</td>\n",
       "      <td>3474</td>\n",
       "      <td>+</td>\n",
       "      <td>PLUS SIGN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>99.836922</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>124</td>\n",
       "      <td>2756</td>\n",
       "      <td>|</td>\n",
       "      <td>VERTICAL LINE</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>99.858139</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>62</td>\n",
       "      <td>2735</td>\n",
       "      <td>&gt;</td>\n",
       "      <td>GREATER-THAN SIGN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>99.868021</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>176</td>\n",
       "      <td>2114</td>\n",
       "      <td>°</td>\n",
       "      <td>DEGREE SIGN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>99.902545</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>91</td>\n",
       "      <td>1903</td>\n",
       "      <td>[</td>\n",
       "      <td>LEFT SQUARE BRACKET</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>99.916416</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>93</td>\n",
       "      <td>1899</td>\n",
       "      <td>]</td>\n",
       "      <td>RIGHT SQUARE BRACKET</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>99.923277</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Code   Count Char                                    CharName  isAlpha  \\\n",
       "18     44  227594    ,                                       COMMA    False   \n",
       "20     46  209020    .                                   FULL STOP    False   \n",
       "23   8217  151057    ’                 RIGHT SINGLE QUOTATION MARK    False   \n",
       "27     39   99110    '                                  APOSTROPHE    False   \n",
       "35     45   70047    -                                HYPHEN-MINUS    False   \n",
       "40     32   59143                                            SPACE    False   \n",
       "41    160   55700                                   NO-BREAK SPACE    False   \n",
       "42     58   55099    :                                       COLON    False   \n",
       "48     41   42072    )                           RIGHT PARENTHESIS    False   \n",
       "49     40   42034    (                            LEFT PARENTHESIS    False   \n",
       "66     63   21147    ?                               QUESTION MARK    False   \n",
       "67     47   21144    /                                     SOLIDUS    False   \n",
       "69     37   16513    %                                PERCENT SIGN    False   \n",
       "71   8364   12783    €                                   EURO SIGN    False   \n",
       "72    187   11678    »  RIGHT-POINTING DOUBLE ANGLE QUOTATION MARK    False   \n",
       "73    171   11230    «   LEFT-POINTING DOUBLE ANGLE QUOTATION MARK    False   \n",
       "75     34   10079    \"                              QUOTATION MARK    False   \n",
       "79     10    8497   \\n                                     CHAR 10    False   \n",
       "81     33    7824    !                            EXCLAMATION MARK    False   \n",
       "82   8230    7816    …                         HORIZONTAL ELLIPSIS    False   \n",
       "83      9    5979   \\t                                      CHAR 9    False   \n",
       "86     59    4293    ;                                   SEMICOLON    False   \n",
       "88   8211    3996    –                                     EN DASH    False   \n",
       "90     42    3682    *                                    ASTERISK    False   \n",
       "92     43    3474    +                                   PLUS SIGN    False   \n",
       "94    124    2756    |                               VERTICAL LINE    False   \n",
       "95     62    2735    >                           GREATER-THAN SIGN    False   \n",
       "99    176    2114    °                                 DEGREE SIGN    False   \n",
       "101    91    1903    [                         LEFT SQUARE BRACKET    False   \n",
       "102    93    1899    ]                        RIGHT SQUARE BRACKET    False   \n",
       "\n",
       "     isDigit  isSpace    Percent   Name  \n",
       "18     False    False  87.111540  False  \n",
       "20     False    False  88.665295  False  \n",
       "23     False    False  90.437958  False  \n",
       "27     False    False  92.088362  False  \n",
       "35     False    False  94.560573  False  \n",
       "40     False     True  95.668293   True  \n",
       "41     False     True  95.869548   True  \n",
       "42     False    False  96.068632  False  \n",
       "48     False    False  97.058604  False  \n",
       "49     False    False  97.210481  False  \n",
       "66     False    False  99.009008  False  \n",
       "67     False    False  99.085406  False  \n",
       "69     False    False  99.211076  False  \n",
       "71     False    False  99.304055  False  \n",
       "72     False    False  99.346250  False  \n",
       "73     False    False  99.386826  False  \n",
       "75     False    False  99.461377  False  \n",
       "79     False     True  99.590831   True  \n",
       "81     False    False  99.649122  False  \n",
       "82     False    False  99.677363  False  \n",
       "83     False     True  99.698966   True  \n",
       "86     False    False  99.754852  False  \n",
       "88     False    False  99.784314  False  \n",
       "90     False    False  99.811442  False  \n",
       "92     False    False  99.836922  False  \n",
       "94     False    False  99.858139  False  \n",
       "95     False    False  99.868021  False  \n",
       "99     False    False  99.902545  False  \n",
       "101    False    False  99.916416  False  \n",
       "102    False    False  99.923277  False  "
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "charset = loadCharset(rootdir)\n",
    "separatorChars = listSeparatorChars(charset)\n",
    "separatorChars[:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the tokenizer behavior with each separator char :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy_InitWithTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [],
   "source": [
    "def searchCharInTokens(dataset,nlp,char,count):\n",
    "    dataset4c = sampleTextBlocksWithChar(dataset,char,count)    \n",
    "    listSplits = []\n",
    "    listBefore = []\n",
    "    listAfter = []\n",
    "    for rowidx,text in dataset4c[\"Text\"].iteritems():\n",
    "        doc = nlp(text)\n",
    "        splits = True\n",
    "        before = \"\"\n",
    "        after = \"\"\n",
    "        for idx,token in enumerate(doc):\n",
    "            if token.text == char:\n",
    "                before = \"\" if idx==0 else doc[idx-1].text\n",
    "                after = \"\" if idx==(len(doc)-1) else doc[idx+1].text\n",
    "                break\n",
    "            elif char in token.text:\n",
    "                parts = token.text.split(char)\n",
    "                before = parts[0]\n",
    "                if before == \"\":\n",
    "                    before = \"\" if idx==0 else doc[idx-1].text + \"<<\"\n",
    "                after = parts[1]\n",
    "                if after == \"\":\n",
    "                    after = \"\" if idx==(len(doc)-1) else \">>\" + doc[idx+1].text\n",
    "                splits = False\n",
    "                break        \n",
    "        listSplits.append(splits)\n",
    "        listBefore.append(before)\n",
    "        listAfter.append(after)        \n",
    "    dataset4c[\"Splits\"] = listSplits\n",
    "    dataset4c[\"Before\"] = listBefore\n",
    "    dataset4c[\"After\"] = listAfter\n",
    "    return dataset4c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SiteIndex</th>\n",
       "      <th>RowIndex</th>\n",
       "      <th>Text</th>\n",
       "      <th>WordsCount</th>\n",
       "      <th>Context</th>\n",
       "      <th>Splits</th>\n",
       "      <th>Before</th>\n",
       "      <th>After</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>146797</th>\n",
       "      <td>89</td>\n",
       "      <td>16624</td>\n",
       "      <td>Documents d'informations : Document d'Informat...</td>\n",
       "      <td>63</td>\n",
       "      <td>rmations Clés (DIC) - Gan Performance Ret</td>\n",
       "      <td>True</td>\n",
       "      <td>)</td>\n",
       "      <td>Gan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200382</th>\n",
       "      <td>113</td>\n",
       "      <td>6006</td>\n",
       "      <td>Le tremblement de terre de magnitude 5,2, surv...</td>\n",
       "      <td>41</td>\n",
       "      <td>ire de Chinon (Indre-et-Loire), a déclaré</td>\n",
       "      <td>False</td>\n",
       "      <td>Indre</td>\n",
       "      <td>et</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206538</th>\n",
       "      <td>115</td>\n",
       "      <td>10611</td>\n",
       "      <td>Pour trouver l'assurance-vie qui correspond à ...</td>\n",
       "      <td>182</td>\n",
       "      <td>trouver l'assurance-vie qui correspond à</td>\n",
       "      <td>True</td>\n",
       "      <td>assurance</td>\n",
       "      <td>vie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196314</th>\n",
       "      <td>109</td>\n",
       "      <td>8575</td>\n",
       "      <td>Monte Paschi Banque - Livret de développement ...</td>\n",
       "      <td>10</td>\n",
       "      <td>Monte Paschi Banque - Livret de développe</td>\n",
       "      <td>True</td>\n",
       "      <td>Banque</td>\n",
       "      <td>Livret</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207225</th>\n",
       "      <td>115</td>\n",
       "      <td>26098</td>\n",
       "      <td>- Label d’Excellence 2014 pour le compte coura...</td>\n",
       "      <td>20</td>\n",
       "      <td>- Label d’Excellence</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "      <td>Label</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44948</th>\n",
       "      <td>26</td>\n",
       "      <td>9943</td>\n",
       "      <td>Vous souhaitez effectuer une demande de micro-...</td>\n",
       "      <td>32</td>\n",
       "      <td>une demande de micro-crédit en ligne aupr</td>\n",
       "      <td>False</td>\n",
       "      <td>micro</td>\n",
       "      <td>crédit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209761</th>\n",
       "      <td>117</td>\n",
       "      <td>6680</td>\n",
       "      <td>L’assurance-vie (fonds en euros ou unités de c...</td>\n",
       "      <td>14</td>\n",
       "      <td>L’assurance-vie (fonds en euros</td>\n",
       "      <td>True</td>\n",
       "      <td>assurance</td>\n",
       "      <td>vie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68992</th>\n",
       "      <td>44</td>\n",
       "      <td>24865</td>\n",
       "      <td>*les dispositions s'appliquent également, comp...</td>\n",
       "      <td>48</td>\n",
       "      <td>territoires d'outre-mer ou à l'étranger*</td>\n",
       "      <td>True</td>\n",
       "      <td>outre</td>\n",
       "      <td>mer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26291</th>\n",
       "      <td>19</td>\n",
       "      <td>4356</td>\n",
       "      <td>Cofondateur du Palais de Tokyo, ancien directe...</td>\n",
       "      <td>63</td>\n",
       "      <td>directeur des Beaux-Arts de Paris, ce th</td>\n",
       "      <td>False</td>\n",
       "      <td>Beaux</td>\n",
       "      <td>Arts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158501</th>\n",
       "      <td>95</td>\n",
       "      <td>10283</td>\n",
       "      <td>ING peut percevoir des rétrocessions de la par...</td>\n",
       "      <td>112</td>\n",
       "      <td>ment à l’article 314-76 du règlement géné</td>\n",
       "      <td>True</td>\n",
       "      <td>314</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181780</th>\n",
       "      <td>103</td>\n",
       "      <td>575</td>\n",
       "      <td>L'assurance pour les 0-3 ans non scolarisés, à...</td>\n",
       "      <td>22</td>\n",
       "      <td>assurance pour les 0-3 ans non scolarisés</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214557</th>\n",
       "      <td>123</td>\n",
       "      <td>7323</td>\n",
       "      <td>Notre point d’accueil Sofinco Schiltigheim vou...</td>\n",
       "      <td>35</td>\n",
       "      <td>s propose des rendez-vous personnalisés p</td>\n",
       "      <td>False</td>\n",
       "      <td>rendez</td>\n",
       "      <td>vous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125696</th>\n",
       "      <td>75</td>\n",
       "      <td>10004</td>\n",
       "      <td>Partenaire bancaire des associations, des étab...</td>\n",
       "      <td>117</td>\n",
       "      <td>tablissements médico-sociaux et scolaires</td>\n",
       "      <td>False</td>\n",
       "      <td>médico</td>\n",
       "      <td>sociaux</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64937</th>\n",
       "      <td>42</td>\n",
       "      <td>2298</td>\n",
       "      <td>La moyenne mobile arithmétique exponentielle p...</td>\n",
       "      <td>42</td>\n",
       "      <td>re de période est en-dessous de est au-de</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "      <td>dessous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115630</th>\n",
       "      <td>71</td>\n",
       "      <td>12245</td>\n",
       "      <td>Pour souscrire votre crédit renouvelable et la...</td>\n",
       "      <td>71</td>\n",
       "      <td>ive associée, rendez-vous dans votre maga</td>\n",
       "      <td>False</td>\n",
       "      <td>rendez</td>\n",
       "      <td>vous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153180</th>\n",
       "      <td>92</td>\n",
       "      <td>16862</td>\n",
       "      <td>Le prix du sous-jacent pour lequel le seuil de...</td>\n",
       "      <td>24</td>\n",
       "      <td>Le prix du sous-jacent pour lequel l</td>\n",
       "      <td>False</td>\n",
       "      <td>sous</td>\n",
       "      <td>jacent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199525</th>\n",
       "      <td>113</td>\n",
       "      <td>564</td>\n",
       "      <td>ENTRETIEN EXCLUSIF. « François de Rugy a voulu...</td>\n",
       "      <td>28</td>\n",
       "      <td>nne », assure son ex-directrice de cabine</td>\n",
       "      <td>False</td>\n",
       "      <td>ex</td>\n",
       "      <td>directrice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54421</th>\n",
       "      <td>35</td>\n",
       "      <td>6662</td>\n",
       "      <td>Jusqu'à 42 euros la nuit pour recharger sa voi...</td>\n",
       "      <td>18</td>\n",
       "      <td>sur une borne libre-service à Lyon !</td>\n",
       "      <td>False</td>\n",
       "      <td>libre</td>\n",
       "      <td>service</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217570</th>\n",
       "      <td>124</td>\n",
       "      <td>5169</td>\n",
       "      <td>Comme tous les contrats de travail, les CDD sa...</td>\n",
       "      <td>74</td>\n",
       "      <td>riode d’essai, c’est-à-dire un laps de te</td>\n",
       "      <td>False</td>\n",
       "      <td>c’est</td>\n",
       "      <td>à</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39563</th>\n",
       "      <td>24</td>\n",
       "      <td>106735</td>\n",
       "      <td>Palmarès 2016 des assurance-vie sur trois ans</td>\n",
       "      <td>7</td>\n",
       "      <td>s 2016 des assurance-vie sur trois ans</td>\n",
       "      <td>False</td>\n",
       "      <td>assurance</td>\n",
       "      <td>vie</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        SiteIndex  RowIndex  \\\n",
       "146797         89     16624   \n",
       "200382        113      6006   \n",
       "206538        115     10611   \n",
       "196314        109      8575   \n",
       "207225        115     26098   \n",
       "44948          26      9943   \n",
       "209761        117      6680   \n",
       "68992          44     24865   \n",
       "26291          19      4356   \n",
       "158501         95     10283   \n",
       "181780        103       575   \n",
       "214557        123      7323   \n",
       "125696         75     10004   \n",
       "64937          42      2298   \n",
       "115630         71     12245   \n",
       "153180         92     16862   \n",
       "199525        113       564   \n",
       "54421          35      6662   \n",
       "217570        124      5169   \n",
       "39563          24    106735   \n",
       "\n",
       "                                                     Text  WordsCount  \\\n",
       "146797  Documents d'informations : Document d'Informat...          63   \n",
       "200382  Le tremblement de terre de magnitude 5,2, surv...          41   \n",
       "206538  Pour trouver l'assurance-vie qui correspond à ...         182   \n",
       "196314  Monte Paschi Banque - Livret de développement ...          10   \n",
       "207225  - Label d’Excellence 2014 pour le compte coura...          20   \n",
       "44948   Vous souhaitez effectuer une demande de micro-...          32   \n",
       "209761  L’assurance-vie (fonds en euros ou unités de c...          14   \n",
       "68992   *les dispositions s'appliquent également, comp...          48   \n",
       "26291   Cofondateur du Palais de Tokyo, ancien directe...          63   \n",
       "158501  ING peut percevoir des rétrocessions de la par...         112   \n",
       "181780  L'assurance pour les 0-3 ans non scolarisés, à...          22   \n",
       "214557  Notre point d’accueil Sofinco Schiltigheim vou...          35   \n",
       "125696  Partenaire bancaire des associations, des étab...         117   \n",
       "64937   La moyenne mobile arithmétique exponentielle p...          42   \n",
       "115630  Pour souscrire votre crédit renouvelable et la...          71   \n",
       "153180  Le prix du sous-jacent pour lequel le seuil de...          24   \n",
       "199525  ENTRETIEN EXCLUSIF. « François de Rugy a voulu...          28   \n",
       "54421   Jusqu'à 42 euros la nuit pour recharger sa voi...          18   \n",
       "217570  Comme tous les contrats de travail, les CDD sa...          74   \n",
       "39563       Palmarès 2016 des assurance-vie sur trois ans           7   \n",
       "\n",
       "                                          Context  Splits     Before  \\\n",
       "146797  rmations Clés (DIC) - Gan Performance Ret    True          )   \n",
       "200382  ire de Chinon (Indre-et-Loire), a déclaré   False      Indre   \n",
       "206538   trouver l'assurance-vie qui correspond à    True  assurance   \n",
       "196314  Monte Paschi Banque - Livret de développe    True     Banque   \n",
       "207225                      - Label d’Excellence     True              \n",
       "44948   une demande de micro-crédit en ligne aupr   False      micro   \n",
       "209761           L’assurance-vie (fonds en euros     True  assurance   \n",
       "68992    territoires d'outre-mer ou à l'étranger*    True      outre   \n",
       "26291    directeur des Beaux-Arts de Paris, ce th   False      Beaux   \n",
       "158501  ment à l’article 314-76 du règlement géné    True        314   \n",
       "181780  assurance pour les 0-3 ans non scolarisés    True          0   \n",
       "214557  s propose des rendez-vous personnalisés p   False     rendez   \n",
       "125696  tablissements médico-sociaux et scolaires   False     médico   \n",
       "64937   re de période est en-dessous de est au-de   False         en   \n",
       "115630  ive associée, rendez-vous dans votre maga   False     rendez   \n",
       "153180       Le prix du sous-jacent pour lequel l   False       sous   \n",
       "199525  nne », assure son ex-directrice de cabine   False         ex   \n",
       "54421        sur une borne libre-service à Lyon !   False      libre   \n",
       "217570  riode d’essai, c’est-à-dire un laps de te   False      c’est   \n",
       "39563      s 2016 des assurance-vie sur trois ans   False  assurance   \n",
       "\n",
       "             After  \n",
       "146797         Gan  \n",
       "200382          et  \n",
       "206538         vie  \n",
       "196314      Livret  \n",
       "207225       Label  \n",
       "44948       crédit  \n",
       "209761         vie  \n",
       "68992          mer  \n",
       "26291         Arts  \n",
       "158501          76  \n",
       "181780           3  \n",
       "214557        vous  \n",
       "125696     sociaux  \n",
       "64937      dessous  \n",
       "115630        vous  \n",
       "153180      jacent  \n",
       "199525  directrice  \n",
       "54421      service  \n",
       "217570           à  \n",
       "39563          vie  "
      ]
     },
     "execution_count": 437,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char = \"-\"\n",
    "dataset4c = searchCharInTokens(dataset,nlp,char,10000)\n",
    "dataset4c.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most frequent chars before, after and around a separator when the tokenizer splits in three tokens, or doesn't split at all :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exploreBeforeAfterSeparator(dataset4c,splits,columns):\n",
    "    return dataset4c[dataset4c[\"Splits\"] == splits].groupby(columns).agg({'Text':['count']})[\"Text\"].sort_values(\"count\",ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Before</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>assurance</th>\n",
       "      <td>219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Etats</th>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jean</th>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>)</th>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Saint</th>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>:</th>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>faut</th>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Assurance</th>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peut</th>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e</th>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Peut</th>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>États</th>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mes</th>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PEA</th>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sont</th>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ligne</th>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Faut</th>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ex</th>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dois</th>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Banque</th>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Outre</th>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Notre</th>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Paris</th>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Arkéa</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>?</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Contactez</th>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           count\n",
       "Before          \n",
       "             300\n",
       "assurance    219\n",
       "Etats        121\n",
       "Jean          97\n",
       ")             91\n",
       "Saint         89\n",
       ":             63\n",
       "faut          53\n",
       "Assurance     47\n",
       "peut          46\n",
       "2019          45\n",
       "e             41\n",
       "Peut          40\n",
       "États         39\n",
       "mes           36\n",
       "PEA           34\n",
       "sont          34\n",
       "ligne         29\n",
       "Faut          29\n",
       "ex            28\n",
       "2018          26\n",
       "dois          24\n",
       "Banque        24\n",
       "Outre         22\n",
       "Notre         22\n",
       "Paris         21\n",
       "Arkéa         20\n",
       "E             20\n",
       "?             20\n",
       "Contactez     19"
      ]
     },
     "execution_count": 439,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beforeSplits = exploreBeforeAfterSeparator(dataset4c,True,[\"Before\"])\n",
    "beforeSplits.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Mis</th>\n",
       "      <td>425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vous</th>\n",
       "      <td>341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vie</th>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unis</th>\n",
       "      <td>161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>il</th>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nous</th>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>on</th>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t</th>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>je</th>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ils</th>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Le</th>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>La</th>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>le</th>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Les</th>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Moyen</th>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Crédit</th>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vie</th>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PME</th>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Oney</th>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Court</th>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>placements</th>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Banque</th>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>en</th>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Long</th>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>par</th>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>les</th>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Assurance</th>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>de</th>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            count\n",
       "After            \n",
       "Mis           425\n",
       "vous          341\n",
       "vie           210\n",
       "Unis          161\n",
       "il            147\n",
       "nous          117\n",
       "on             73\n",
       "t              67\n",
       "je             65\n",
       "ils            62\n",
       "Le             54\n",
       "La             53\n",
       "le             49\n",
       "Les            44\n",
       "Moyen          41\n",
       "Crédit         40\n",
       "Vie            38\n",
       "2019           37\n",
       "PME            37\n",
       "Oney           36\n",
       "Court          36\n",
       "placements     35\n",
       "Banque         35\n",
       "en             33\n",
       "Long           32\n",
       "1              31\n",
       "par            31\n",
       "les            28\n",
       "Assurance      26\n",
       "de             25"
      ]
     },
     "execution_count": 440,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "afterSplits = exploreBeforeAfterSeparator(dataset4c,True,[\"After\"])\n",
    "afterSplits.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Before</th>\n",
       "      <th>After</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>assurance</th>\n",
       "      <th>vie</th>\n",
       "      <td>205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Etats</th>\n",
       "      <th>Unis</th>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>faut</th>\n",
       "      <th>il</th>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>États</th>\n",
       "      <th>Unis</th>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Peut</th>\n",
       "      <th>on</th>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Assurance</th>\n",
       "      <th>Vie</th>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PEA</th>\n",
       "      <th>PME</th>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mes</th>\n",
       "      <th>placements</th>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Faut</th>\n",
       "      <th>il</th>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dois</th>\n",
       "      <th>je</th>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Notre</th>\n",
       "      <th>Dame</th>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <th>2020</th>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sont</th>\n",
       "      <th>ils</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <th>2019</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Contactez</th>\n",
       "      <th>nous</th>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peut</th>\n",
       "      <th>il</th>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jean</th>\n",
       "      <th>Michel</th>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peut</th>\n",
       "      <th>on</th>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jean</th>\n",
       "      <th>Pierre</th>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sommes</th>\n",
       "      <th>nous</th>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bonus</th>\n",
       "      <th>malus</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Outre</th>\n",
       "      <th>mer</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>connectez</th>\n",
       "      <th>vous</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ouest</th>\n",
       "      <th>France</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CMU</th>\n",
       "      <th>C</th>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Renseignez</th>\n",
       "      <th>vous</th>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pierre</th>\n",
       "      <th>papier</th>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>06h00</th>\n",
       "      <th>Mis</th>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sont</th>\n",
       "      <th>elles</th>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>)</th>\n",
       "      <th>Le</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       count\n",
       "Before     After            \n",
       "assurance  vie           205\n",
       "Etats      Unis          121\n",
       "faut       il             53\n",
       "États      Unis           39\n",
       "Peut       on             39\n",
       "Assurance  Vie            36\n",
       "PEA        PME            33\n",
       "mes        placements     33\n",
       "Faut       il             29\n",
       "dois       je             24\n",
       "Notre      Dame           22\n",
       "2019       2020           22\n",
       "sont       ils            20\n",
       "2018       2019           20\n",
       "Contactez  nous           19\n",
       "peut       il             19\n",
       "Jean       Michel         18\n",
       "peut       on             18\n",
       "Jean       Pierre         17\n",
       "sommes     nous           17\n",
       "bonus      malus          16\n",
       "Outre      mer            16\n",
       "connectez  vous           16\n",
       "Ouest      France         16\n",
       "CMU        C              15\n",
       "Renseignez vous           15\n",
       "pierre     papier         15\n",
       "06h00      Mis            14\n",
       "sont       elles          14\n",
       ")          Le             13"
      ]
     },
     "execution_count": 441,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aroundSplits = exploreBeforeAfterSeparator(dataset4c,True,[\"Before\",\"After\"])\n",
    "aroundSplits.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Before</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>est&lt;&lt;</th>\n",
       "      <td>197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ci</th>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>non</th>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e</th>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>au</th>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rendez</th>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start</th>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sous</th>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>plus</th>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>celui</th>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>est</th>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>assurance</th>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>co</th>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Assurance</th>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>celle</th>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c’est</th>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Au</th>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compte</th>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>camping</th>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peut</th>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a&lt;&lt;</th>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sur</th>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lui</th>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anti</th>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vous</th>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Royaume</th>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>puis</th>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deux</th>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mes</th>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mi</th>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           count\n",
       "Before          \n",
       "est<<        197\n",
       "ci           160\n",
       "non          124\n",
       "e            122\n",
       "au           118\n",
       "rendez       114\n",
       "start        107\n",
       "sous         107\n",
       "plus         100\n",
       "celui         93\n",
       "est           91\n",
       "assurance     80\n",
       "co            72\n",
       "Assurance     63\n",
       "celle         60\n",
       "c’est         55\n",
       "Au            53\n",
       "compte        52\n",
       "camping       48\n",
       "peut          45\n",
       "a<<           43\n",
       "sur           42\n",
       "lui           40\n",
       "anti          37\n",
       "vous          34\n",
       "Royaume       32\n",
       "puis          32\n",
       "deux          30\n",
       "mes           29\n",
       "mi            29"
      ]
     },
     "execution_count": 442,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beforeNoSplit = exploreBeforeAfterSeparator(dataset4c,False,[\"Before\"])\n",
    "beforeNoSplit.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ci</th>\n",
       "      <td>260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ce</th>\n",
       "      <td>213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vous</th>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vie</th>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>delà</th>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>up</th>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>à</th>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>même</th>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dessous</th>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>values</th>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dessus</th>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>être</th>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>il</th>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t</th>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>je</th>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mail</th>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>car</th>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mesure</th>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roues</th>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>de</th>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>value</th>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jacent</th>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Uni</th>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>après</th>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>elle</th>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>titres</th>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>forme</th>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>end</th>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>faire</th>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>en</th>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         count\n",
       "After         \n",
       "ci         260\n",
       "ce         213\n",
       "vous       154\n",
       "vie        151\n",
       "delà       133\n",
       "up         114\n",
       "à          112\n",
       "même       100\n",
       "dessous     95\n",
       "values      82\n",
       "dessus      79\n",
       "être        67\n",
       "il          62\n",
       "t           62\n",
       "je          58\n",
       "mail        56\n",
       "car         47\n",
       "mesure      41\n",
       "roues       37\n",
       "de          36\n",
       "value       33\n",
       "jacent      32\n",
       "Uni         32\n",
       "après       32\n",
       "elle        29\n",
       "titres      28\n",
       "forme       26\n",
       "end         24\n",
       "faire       24\n",
       "en          23"
      ]
     },
     "execution_count": 443,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "afterNoSplit = exploreBeforeAfterSeparator(dataset4c,False,[\"After\"])\n",
    "afterNoSplit.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Before</th>\n",
       "      <th>After</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>est&lt;&lt;</th>\n",
       "      <th>ce</th>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rendez</th>\n",
       "      <th>vous</th>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start</th>\n",
       "      <th>up</th>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>celui</th>\n",
       "      <th>ci</th>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ci</th>\n",
       "      <th>dessous</th>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>au</th>\n",
       "      <th>delà</th>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>assurance</th>\n",
       "      <th>vie</th>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>plus</th>\n",
       "      <th>values</th>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Assurance</th>\n",
       "      <th>vie</th>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>celle</th>\n",
       "      <th>ci</th>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>est</th>\n",
       "      <th>il</th>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e</th>\n",
       "      <th>mail</th>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c’est</th>\n",
       "      <th>à</th>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Au</th>\n",
       "      <th>delà</th>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ci</th>\n",
       "      <th>dessus</th>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peut</th>\n",
       "      <th>être</th>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a&lt;&lt;</th>\n",
       "      <th>t</th>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>camping</th>\n",
       "      <th>car</th>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sur</th>\n",
       "      <th>mesure</th>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lui</th>\n",
       "      <th>même</th>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vous</th>\n",
       "      <th>même</th>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Royaume</th>\n",
       "      <th>Uni</th>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sous</th>\n",
       "      <th>jacent</th>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>puis</th>\n",
       "      <th>je</th>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>au</th>\n",
       "      <th>dessus</th>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deux</th>\n",
       "      <th>roues</th>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>est</th>\n",
       "      <th>elle</th>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ci</th>\n",
       "      <th>après</th>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rendez</th>\n",
       "      <th>vous</th>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compte</th>\n",
       "      <th>titres</th>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   count\n",
       "Before    After         \n",
       "est<<     ce         192\n",
       "rendez    vous       114\n",
       "start     up         107\n",
       "celui     ci          93\n",
       "ci        dessous     81\n",
       "au        delà        81\n",
       "assurance vie         79\n",
       "plus      values      74\n",
       "Assurance vie         61\n",
       "celle     ci          60\n",
       "est       il          56\n",
       "e         mail        55\n",
       "c’est     à           55\n",
       "Au        delà        51\n",
       "ci        dessus      46\n",
       "peut      être        45\n",
       "a<<       t           43\n",
       "camping   car         43\n",
       "sur       mesure      41\n",
       "lui       même        40\n",
       "vous      même        34\n",
       "Royaume   Uni         32\n",
       "sous      jacent      32\n",
       "puis      je          32\n",
       "au        dessus      31\n",
       "deux      roues       30\n",
       "est       elle        29\n",
       "ci        après       29\n",
       "Rendez    vous        28\n",
       "compte    titres      28"
      ]
     },
     "execution_count": 449,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aroundNoSplit = exploreBeforeAfterSeparator(dataset4c,False,[\"Before\",\"After\"])\n",
    "aroundNoSplit.head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find examples in context :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "123583          onsommation : qu’est-ce que c’est ?\n",
       "185271                  Qu’est-ce qu’un contrat d'a\n",
       "164688                  Qu'est-ce que la défiscalis\n",
       "177974    ébut d’année. Qu’est-ce que le fichier de\n",
       "8761                      Qu'est-ce qu'un artisan ?\n",
       "151572            Pourquoi est-ce important : lors \n",
       "17323                   Qu'est-ce qu'un crédit reno\n",
       "188674                  Qu’est-ce que le tiers paya\n",
       "43241     r. Mais alors qu’est-ce qu’un CFD et comm\n",
       "132609                  Qu'est-ce que la banque à d\n",
       "1327                    Qu’est-ce qu’une résidence \n",
       "186802                  Qu'est-ce qu'un conducteur \n",
       "132018     » PTZ 2019 | Qu’est-ce que le Prêt à Tau\n",
       "178253               7. Qu’est-ce que le Transfert \n",
       "72771                   Qu’est-ce que la prévoyance\n",
       "5504                       iant Cthulhu, qu’est-ce…\n",
       "138234                  Qu’est-ce que le bonus malu\n",
       "159029                  Qu’est-ce qui change avec m\n",
       "17453                   Qu'est-ce que l'assurance p\n",
       "123736                  Qu'est-ce que le délai de f\n",
       "107750                  Qu'est-ce que la règle des \n",
       "211099                  Qu'est-ce qu'un enfant à ch\n",
       "159905     Question 2 : Qu'est-ce que le Prêt Vert \n",
       "108741             Le squat : qu’est-ce que c’est ?\n",
       "8791                    Qu'est-ce que le taux de ba\n",
       "52781                      Qu’est-ce qu’un cookie ?\n",
       "71257     surés (FVA) : qu’est-ce que c’est ? | All\n",
       "151568            Pourquoi est-ce important : un co\n",
       "134847                  Qu'est-ce que la caution d'\n",
       "59264              Vidéo : est-ce le bon moment pou\n",
       "Name: Context, dtype: object"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset4c[(dataset4c[\"Before\"]==\"est<<\") & (dataset4c[\"After\"]==\"ce\")][\"Context\"].sample(30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spacy",
   "language": "python",
   "name": "spacy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
